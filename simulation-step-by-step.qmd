# Step-by-step simulation

The following chapter is separated in two parts:

1. Simulation experiment for one setting by choosing between
      - Parallel or stepped wedge designs   
      - Studies with different fidelity patterns
2. Simulation experiments to compare of several fidelity patterns

@fig-workflow provides an overview of the simulation workflow.

```{r, out.width='80%', echo = F}
#| fig-cap: "Overview of simulation workflow"
#| label: fig-workflow 
knitr::include_graphics("img/workflow_2.png")
```

## Simulation experiment for one setting {#sec-simintro}

According to the inner frame of @fig-workflow, several specifications have to be made to evaluate the performance of a chosen design and fidelity pattern. 

Within each simulation-experiment, the steps *data sampling* and *effect estimation* will be repeated (further explanation see @sec-statsdetails.) To simplify the process of the whole simulation-experiment, we packaged the code into the R package {fidelitysim}. 

The function `fidelitysim::simulation()` includes the steps: data sampling for a specific design and existing implementation error, effect estimation, performance measures calculation and the following parameters are needed as arguments to the function:  
 
  - number of repeats for the simulation
  - chosen design (including study design, number of cluster, time points and individuals per cluster)
  - model parameters (effect, variances, ...)
  - two design matrices which indicates whether deviation from perfect situations are assumed or not
  
The outputs of the function are: 
  
  - effect estimates
  - performance measures  
  
After repeating the steps of the simulation the obtained effect estimates can be 
evaluated for the performance of the model. The following performance measures of a simulation are provided: 

- Bias: mean deviation of the estimates from the true value of the parameter of 
  interest (intervention effect) is an indicator of accuracy  
  
- Coverage: measurement used to control the Type I error rate for testing the 
  null hypothesis (H0) of no effect  
  
- Power: proportion of simulation samples in which the H0 of no effect is rejected 
  at a significance level of $\alpha$ when H0 is false (is related to the empirical Type II error rate).  

In the following, we will show an example of a whole simulation experiment for a parallel cluster randomized trial. Further we will point out necessary adaptions for stepped-wedge designs (regarding the parameter setting). 

First, make sure that necessary packages are loaded (and to obtain the same results) indicate a seed for the simulation:

```{r pkgs}
# load necessary packages
library(fidelitysim)
library(samplingDataCRT)

# seed
set.seed(1234)
```

One setting includes the specification of:  

1. Study design
2. Assumptions about fidelity pattern
3. Model parameter
4. Iterations of the simulation

and finally, 

5. the simulation experiment can be performed.


### Study design {#sec-studydesign}

Based on the study setup, the following parameters for the study design need to be defined: 

- No. of clusters (e.g hospitals)
- No. of individuals per cluster (and time point) as the cluster size
- No. of time points the cluster were followed
- Design type controls if individuals will be followed over time (cross-sectional or longitudinal): cross-sectional type, which indicates trials where individuals within the cluster can change over time points (however this design indicator is not necessary for conducting the design matrix)

A design matrix according the study design has to be determined by the function `designMatrix()`. Here, two arguments are specific for the different types of studies. If the `design = 'parallel'`, then the parameter `nSW` indicates the number of clusters as being the control group. 
If choosing `design = 'SWD'` (which is also set by default), the parameter `nSW` indicates the number of cluster-switches per time point from control to intervention group (which highly dependent on the number of clusters and time points).

For our example we will use the following parameter: 

- Number of clusters: 6
- Cluster size: 10  
- Number of time points: 7 
- Cross-sectional design

and 3 clusters are in the control and 3 clusters in the intervention group.

In the next step we determine the corresponding design matrix for a parallel cluster randomized study with this specific set of design parameters as follows: 

```{r design-prll}
## Design matrix ##

I <- 6      # number of clusters
J <- 10     # number of individuals per cluster (used later in simulation-step)
K <- 7      # number of time points
Sw <- 1     # number of cluster switches per time point can be manually set
type <- "cross-sec" #Cross-sectional design, indicates that 
#individuals within the cluster can change over time points

# design matrix for parallel design
(designMat_prll <- designMatrix(
  nC = I, nT = K, nSw = round(I / 2),
  design = "parallel"
))

```


### Assumptions about fidelity pattern

The following step is a central part of this tutorial. We want to examine different fidelity patterns and their implications for the study effects. 

To simulate a specific fidelity pattern, a second design matrix indicating the pattern of fidelity has to be provided and indicates if there are deviations from the perfect situation (100% fidelity) present or not. For the simulation we have to add fractional values according to the chosen fidelity pattern. There are 3 functions within the R-package {fidelitysim} that can be used to specify several fidelity patterns. The patterns can be specified based on a slow, linear or fast increase and the respective start and end value for fidelity. For further explanation of fidelity patterns see @sec-fidpatterns.
The selected fidelity patterns can then be pushed to the design matrix with the R-package
{samplingDataCRT}, for more explanation see @sec-determinediffdesignmatrix.

For our example we use the same design parameters, i.e. parallel cluster randomized trial, 6 timepoints, etc. and assume a linear increase of fidelity from 40% to 80% from the first measurement point after introduction of the intervention to the final measurement point (time point `K`). Based on these parameters we will create a new design matrix `X.A` that incorporates fractional values based on the provided fidelity pattern. This new design matrix will be used as a reference matrix in our simulation.

<!-- ############################ -->

<!-- Further, in the function for the simulation by specifying a second design matrix `X.A`, we can indicate if there are deviations from the perfect situation present or not. Since we simulation perfect situation with no deviation, both arguments for the design matrices `X` and `X.A` are the same within the latter used R-function `simulation()` (see [Simulation experiment]). If deviations from perfect situation should be simulated, a second design matrix to which indicates the pattern of fidelity according to this study design has to be provided as well.  -->

<!-- To consider the deviation from perfect implementation of an intervention  -->
<!-- (100% fidelity) we add fractional values to estimate the degree  -->
<!-- of the deviation and its effect on the study effects.  -->
<!-- Therefor 3 functions in within the R-package {fidelitysim} can be used to specify several fidelity patterns. For explanation of all kind of fidelity patters see [Determine different fidelity patterns].  -->
<!-- The conducted fidelity patterns can then be pushed to the design matrix with the R-package {samplingDataCRT}, see for more explanation [Fidelity patterns].  -->

<!-- Using the same parallel design trial example and assume a linear increase of fidelity from 40% to 80% from time point 1 to the end of trial (time point `K`)  -->


3 arguments have to be specified to determine the fidelity pattern using the provided function `find.Fidelity.linear`: 

```{r params-fidel-prll}
### Fidelity parameters ###

# Fidelity at the begin
Fid.T1 <- 0.4
# Fidelity at the end
Fid.End <- 0.8

# slope for linear function
m <- (Fid.T1 - Fid.End) / (1 - (K - 1))
```


```{r fidel-lin-prll}
# model linear increase
res.lin <- find.Fidelity.linear(time.points = K, Fid.End, Fid.T1)
```

(The application of the other two functions for slow (exponential) and fast (logarithmic) increase are shown in @sec-fidpatterns.)  

Then, we create the new design matrix using the function `implemMatrix.parallel` :    

```{r fidel-matr-prll}
# design matrix of a linear fidelity pattern
(fidelMat_prll <- implemMatrix.parallel(
  nC = I, nT = K, nSw = round(I / 2),
  pattern = res.lin[, "Fidelity.Prozent"] / 100
))
```

This matrix reflect the fidelity pattern including the implementation error (deviation form 100%). Both design matrices are later used for the simulation as arguments `X = designMat_prll` and `X.A = fidelMat_prll` for simulation  @sec-simulexp. In a *perfect* situation - where we assume 100% fidelity at every time point, both matrices are the same. 

### Specifying model parameter {#sec-modelparam}

In addition to the design parameters, we have to define the following model parameters as well:

- Baseline mean of the outcome of interest (e.g. mean quality of life score) $\mu_0$
- Intervention effect (the change of scores after intervention) $\Theta$
- Intra-cluster correlation coefficient ICC (between cluster and error variance $\sigma_c$, $\sigma_e$ )  
-	If applicable: time trend (effect of each time point during followed time points)  

<!-- These values are usually chosen based on expert knowledge.   -->

For our example we use the following model parameter: 

- baseline mean = 10
- intervention effect = 1
- no time trend
- ICC of 0.001


```{r params-prll}
## Model parameter ##

mu.0 <- 10 # Baseline mean of the outcome of interest
theta <- 1 # Intervention effect
betas <- rep(0, K - 1) # no time trend, but could be included

# variability within or error variance (H&H sigma)
sigma.1 <- 2 
# variability within clusters, if longitudina data
sigma.2 <- NULL 
# between clusters variability (H&H tau)
sigma.3 <- sigma.1 * sqrt(0.001 / (1 - 0.001)) 

# resulting ICC
(ICC <- sigma.3^2 / (sigma.3^2 + sigma.1^2))
```


When choosing a longitudinal instead of a cross-sectional design a third variance 
needs to be specified (see for more detail into @sec-sampdatacrt).

### Defining number of iterations for the simulation

In addition to the parameters set above, we need to define the number of iterations for the
simulation. The number determines how often the sampling and estimation should be repeated to finally calculate the performance measures. In the literature 10,000 and 100,000 iterations are recommended to obtain valid results, however, this validity comes at a time cost. In our example we will set n = 1,000 iterations with regard to the computing time (and can be set by the user under consideration of their machine's computational power). 


```{r anzItglobal}

## Number of iterations of the simulation ##
anzSim <- 1000

```


### Simulation experiment {#sec-simulexp} 

Since we set all necessary arguments for the usage of the provided simulation function:

1. Study design
2. Model parameter
3. Indication if there are deviations from perfect situations or not
4. Iterations of the simulation

we can start the simulation by using the provided function `simulation`:

```{r, echo=FALSE}
start_time <- Sys.time()
```


```{r simulation-fidel-prll, warning=FALSE, message=FALSE}
# linear increase of fidelity
res.Simu.parallel.lin <- simulation(
  anzSim = anzSim, #Simulation parameter
  type = type, K = K, J = J, I = I, #design parameter
  sigma.1 = sigma.1, sigma.3 = sigma.3, #model parameters
  mu.0 = mu.0, theta = theta, betas = betas, #model parameters
  X = designMat_prll, X.A = fidelMat_prll #design matrices
)

```


```{r, echo=FALSE}
end_time <- Sys.time()
time.sim <- round(as.numeric((end_time - start_time), units = "mins"),2)
```

For this design setting and number of iteration (n=`r anzSim`), a computational time of `r time.sim` min is needed


The output of the simulation provides a total of n =`r length(res.Simu.parallel.lin)` results, among the following performance parameters (see also @sec-simintro): 

  - Bias
  - Coverage
  - Power  
  
The mean estimate of the intervention effect from all iterations and the 
power of the design can be accessed like this:  

```{r results-fidel-prll}
# mean estimated intervention effect
round(res.Simu.parallel.lin["intervention Mean ."],3)

# estimated power
round(res.Simu.parallel.lin["Power.Intervention"],3)
```

```{r, echo=FALSE}
pow.par.lin<-round(res.Simu.parallel.lin["Power.Intervention"],3)
```

We obtain a power of `r pow.par.lin` to detect an intervention effect of `r theta` within an parallel study with `r I` clusters followed `r K` time points and a cluster size of `r J` when an linear increase of the fidelity from `r Fid.T1*100`% to `r Fid.End*100`% is achieved until end of the study.

## Comparison of several Fidelity patterns

To compare the effect of different fidelity patterns, a repetition of the simulation has to be conducted.

We will continue with our example from before (see @sec-studydesign - @sec-modelparam) and examine in total seven different fidelity patterns. 
We will assume (A) three types of slow increases, (B) one linear increase and (C) three types of fast increases of fidelity for this design setting (see @sec-fidpatterns for further explanation) and compare with the perfect situation. 

<!-- ####### -->

<!-- See again also for fidelity patterns conduction in [Fidelity patterns].  -->
<!-- To compare the effect of different degrees of increasing fidelity after implementation  -->
<!-- against perfect trials, a repetition the simulation experiment for different degrees -->
<!-- of fidelity increase but same settings has to be conducted.   -->
<!-- We take again the example from above: cross-sectional parallel trial with ten  -->
<!-- clusters (5 of them getting the intervention, 5 of them not), 7 time points and ten individuals within each cluster and time point. We also assume a fidelity of `r Fid.T1` at the beginning and `r Fid.End` at the end of trial for the intervention group.  -->
<!-- Here , we investigate on total 7 different fidelity pattern increases, 3 fast increases, 1 linear and 3 slow increases for this design setting (here the results will be shown for a recommended number of repeats of 10.000). -->

```{r, eval=TRUE}
### several Slopes indicating the degree of increase ###
slope.seq<-round(exp(1)^(seq(-2,2,2)),2)
nr.sl<-length(slope.seq)

```

```{r, echo=FALSE}
## Number of repeats within the simulation ##
anzSim <- 10000
```


```{r, echo=FALSE, eval=TRUE}

start_time <- Sys.time()

```

At first, perfect situation simulation (no deviation from 100% implementation).

```{r, warning=F, message=F, eval=FALSE}
################################
# perfect implementation
# no individual or cluster miss
################################

#design matrix of perfect situation
X<-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=round(I/2), design="parallel")
res<-fidelitysim::simulation(
                  anzSim=anzSim, #Simulation parameter
                  type="cross-sec", K=K,J=J,I=I, #design paramter
                  sigma.1=sigma.1,sigma.3=sigma.3, #model parameters
                  mu.0=mu.0, theta=theta,betas=betas,
                  X=X, X.A=X #design matrices
                  )
res<-as.data.frame(t(res))

```

```{r, echo=FALSE, eval=FALSE}
#save results
res.Sim.diffFid<-data.frame()
res.Sim.diffFid<-data.frame(res, 
                            D="perfect", slope=0, sort=1, Fid.Begin=1, Fid.END=1)
```


```{r, echo=FALSE, eval=FALSE}
#save results in file
# file.tmp<-paste("./results/parallel_results_", 1, "_", 1, ".csv", sep="")
# utils::write.table(res.Sim.diffFid, file=file.tmp)
```

Next for (A) several slow increase (reflected by an exponential function):

```{r, warning=F, message=F, eval=FALSE}
###all the other patterns
res.Simu<-data.frame()

#exponential increase
for(sl in 1:nr.sl){#for each slope
    
   #Fidelity pattern
    res.exp<-fidelitysim::find.Fidelity.exp(time.points=K, 
                               Fid.End, Fid.T1, 
                               par.slope=slope.seq[sl])
    #new design matrix
    A1.exp <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), 
                               pattern=res.exp[,"Fidelity.Prozent"]/100)
     #simulation experiment  
    res<-fidelitysim::simulation(anzSim=anzSim,
                    type="cross-sec",  K=K,J=J,I=I,
                    sigma.1=sigma.1,sigma.3=sigma.3,
                    mu.0=mu.0, theta=theta,betas=betas,
                    X=X, X.A=A1.exp
                    )
    res<-as.data.frame(t(res))
    #save results
    res.Simu<-rbind(res.Simu,
                   data.frame( res, 
                      D="exp", slope=slope.seq[sl], sort=2+nr.sl+(nr.sl-sl+1), 
                      Fid.Begin=Fid.T1, Fid.END=Fid.End)
    )

}

```


```{r, echo=FALSE, eval=FALSE}
res.Simu.2<-res.Simu
```


For (B) linear increase:

```{r, warning=F, message=F, eval=FALSE}

##linear increase
m<-(Fid.T1-Fid.End)/(1-(K-1))
#Fidelity pattern
res.lin<-fidelitysim::find.Fidelity.linear(time.points=K, Fid.End, Fid.T1)
#ne design matrix
A1.lin <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), 
                               pattern=res.lin[,"Fidelity.Prozent"]/100)
#simulation experiment
res<-fidelitysim::simulation(anzSim=anzSim,
                type="cross-sec", K=K,J=J,I=I,
                sigma.1=sigma.1,sigma.3=sigma.3,
                mu.0=mu.0, theta=theta,betas=betas,
                X=X, X.A=A1.lin)
res<-as.data.frame(t(res))

```

For (C) several fast increase (reflected by a logarithmic function):

```{r, echo=TRUE, warning=F, message=F, eval=FALSE}
###all the other patterns
res.Simu<-data.frame()

#logistic increase
for(sl in 1:nr.sl){#for each slope
    #Fidelity pattern
    res.log<-fidelitysim::find.Fidelity.log(time.points=K, 
                               Fid.End, Fid.T1, 
                               par.slope=slope.seq[sl])
    #new design matrix
    A1.log <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), 
                                   pattern=res.log[,"Fidelity.Prozent"]/100)
    #simulation experiment
    res<-fidelitysim::simulation(anzSim=anzSim,
                    type="cross-sec", K=K,J=J,I=I,
                    sigma.1=sigma.1,sigma.3=sigma.3,
                    mu.0=mu.0, theta=theta,betas=betas,
                    X=X, X.A=A1.log)
    res<-as.data.frame(t(res))
    #save results
    res.Simu<-rbind(res.Simu,
                   data.frame( res, 
                      D="log", slope=slope.seq[sl], sort=1+sl, 
                      Fid.Begin=Fid.T1, Fid.END=Fid.End)
    )
  }

```


```{r, echo=FALSE, eval=FALSE}
res.Simu.2<-rbind(res.Simu.2,res.Simu)
```


```{r, echo=FALSE, eval=FALSE}
#save results
res.Simu.2<-rbind(res.Simu.2,
                   data.frame( res, 
                    D="linear", slope=0, sort=2+nr.sl , Fid.Begin=Fid.T1, Fid.END=Fid.End)
)

#res.Simu<-as.data.frame(res.Simu)
```


```{r, echo=FALSE, eval=TRUE}

# file.tmp<-paste("./results/parallel_results_", Fid.T1, "_", Fid.End, ".csv", sep="")
# write.table(res.Simu, file=file.tmp)

end_time <- Sys.time()
time.3<-round(as.numeric((end_time - start_time), units = "mins"),2)


```



```{r, echo=FALSE, eval=FALSE}

res.plot<-rbind(res.Simu.2,res.Sim.diffFid)

res.plot<-subset(res.plot, 
                 select=c("Power.Intervention" ,
                          "D", "slope", "sort"
                          , "Fid.END", "Fid.Begin"
                          ))
#function to convert
#as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
#res.plot$Power.Intervention<-as.numeric.factor(res.plot$Power.Intervention)
#res.plot$sort<-as.numeric.factor(res.plot$sort)
#str(res.plot)
#res.plot$slope<-as.factor(res.plot$slope)
#res.plot$sort<-as.factor(res.plot$sort)
#res.plot$Fid.END <-res.plot$Fid.END*100 
#res.plot$Fid.Begin <-res.plot$Fid.Begin*100
#res.plot$D<-factor(res.plot$D, levels=c("log","linear","exp","perfect"))

#txt<-subset(res.plot, subset=(Fid.END==1)&(Fid.Begin==0.4)|(Fid.END==1)&(Fid.Begin==1), select=c("D", 'slope', "sort"))
#txt.xlab<-paste(txt$D, txt$slope, sep="-")[order(txt$sort)]
#txt.xlab<-c("perfect", paste("L+",3:1,sep=""), "L0",paste("L-",1:3,sep=""))

res.plot<-res.plot[with(res.plot, order(sort)), ]
#res.plot

# res.plot.decr<-res.plot[with(res.plot, order(sort, decreasing = TRUE)), ]
# res.plot.decr
```

```{r fig-Simu, fig.width=8, fig.height=8, echo=FALSE, message=FALSE, eval=FALSE}
library(ggplot2)
ggplot(res.plot,
                aes(x=sort, y=Power.Intervention, pch=D))+
  geom_point(size=1)+
  geom_vline(xintercept = nr.sl+2, lty=2, col="grey")+
  geom_hline(yintercept=0.8, lty=2, col="red")+
  theme_bw()+
  theme(legend.position="none",
        #legend.position="bottom",legend.box="vertical",
        #axis.text.x = element_text(angle = 90),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=14),
        axis.title=element_text(size=14),
        axis.ticks.x = element_blank()
        )+
  # scale_x_continuous(labels=c("perfect", "fast", "linear", "slow"),
  #                    breaks=c(1,nr.sl/2+1,nr.sl+2,nr.sl+2+nr.sl/2))+
  labs(#title="SWD Design",
       #shape="Fidelity speed",
       #col="Fidelity change \n (Start:End)", fill="Fidelity Start",
       # pch="",
       x="Increase of Fidelity over time", y="Power")+
#   #guides(fill=TRUE)+
#   #guides(fill = guide_legend(override.aes = list(shape = NA)))+
  ylim(0.25,1)


#ggsave(filename= paste0("img/", lubridate::today(), "-results.Simulation.10000.png"))
```

@fig-sim summarizes the results of the simulation for different fidelity patterns regarding power of the study. The results shown are performed by 10,000 iterations for the simulation to have precise estimates. For this design setting and number of iteration (n=10,000), a computational time of 7 hours is needed.

```{r, out.width='80%', echo = F}
#| fig-cap: "Results of simulation for several fidelity pattern scenarios"
#| label: fig-sim 
knitr::include_graphics("img/results.Simulation.10000.png")
```

