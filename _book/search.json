[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fidelity in Hybrid Implementation Trials: Technical Guidance for Implementation Researchers",
    "section": "",
    "text": "Preface\nThis online tutorial serves as a hands-on guide for researchers to replicate the simulation described in\n[our paper].\nThis supplementary material was designed with regard to support applied researchers (not statisticians) to adapt the simulation with required parameters for their own study. Consequently, the content is split in the following chapters:"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Fidelity in Hybrid Implementation Trials: Technical Guidance for Implementation Researchers",
    "section": "Citation",
    "text": "Citation\nIf you find this work helpful, please cite both the online tutorial and the paper by the reference of the original paper as in:\n[our paper]"
  },
  {
    "objectID": "index.html#comparison-to-other-tools",
    "href": "index.html#comparison-to-other-tools",
    "title": "Fidelity in Hybrid Implementation Trials: Technical Guidance for Implementation Researchers",
    "section": "Comparison to other tools",
    "text": "Comparison to other tools"
  },
  {
    "objectID": "intro.html#required-r-packages",
    "href": "intro.html#required-r-packages",
    "title": "1  Introduction",
    "section": "1.1 Required R packages",
    "text": "1.1 Required R packages\nThe following R packages are needed to run the simulation:\n\n{fidelitysim} (Trutschel and Blatter 2022) - holds packaged code for the simulation experiment\n\nIt uses and builds upon:\n\n{samplingDataCRT} v1.0 (Trutschel and Treutler 2017) - for sampling data matrices\n{lme4} (Bates et al. 2015) - for linear model estimation\n{ggplot2} (Wickham 2016) - for visualizing the results\n\nYou can install the necessary packages by:\n\n# to install {fidelitysim} we need the {remotes}-package\ninstall.packages(\"remotes\")\n\n# then install {fidelitysim} from GitHub\nremotes::install_github(\"INS-Basel/fidelitysim\")\n\nThe other packages are installed from CRAN:\n\n# install packages from CRAN\ninstall.packages(c(\"samplingDataCRT\", \"lme4\", \"ggplot2\"))\n\nConsequently, to start the calculation the package needs to be loaded by:\n\nlibrary(fidelitysim)"
  },
  {
    "objectID": "intro.html#other-considerations",
    "href": "intro.html#other-considerations",
    "title": "1  Introduction",
    "section": "1.2 Other considerations",
    "text": "1.2 Other considerations\nThe local simulation can - depending on the number of clusters - take up to 10-12 hours when the recommended number of iterations of 10,000 is used.\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nR Core Team. 2022. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nTrutschel, Diana, and Catherine Blatter. 2022. fidelitysim: Simulations Experiments for Cluster Randomized Trials Having Fidelity Patterns for Implementation Science Research.\n\n\nTrutschel, Diana, and Hendrik Treutler. 2017. samplingDataCRT: Sampling Data Within Different Study Designs for Cluster Randomized Trials. https://CRAN.R-project.org/package=samplingDataCRT.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org."
  },
  {
<<<<<<< HEAD
    "objectID": "simulation-step-by-step.html",
    "href": "simulation-step-by-step.html",
    "title": "2  Step-by-step simulation",
    "section": "",
    "text": "Workflow diagramme of the simulation\nIn the following the tutorial is separated in two parts, showing the use for:"
  },
  {
=======
>>>>>>> 30fa3fcd4e39a7b91e7df9d2ff5d0e34b1aad3fa
    "objectID": "simulation-step-by-step.html#simulation-experiment-for-one-setting",
    "href": "simulation-step-by-step.html#simulation-experiment-for-one-setting",
    "title": "2  Step-by-step simulation",
    "section": "2.1 Simulation experiment for one setting",
<<<<<<< HEAD
    "text": "2.1 Simulation experiment for one setting\nAccording the [Workflow diagramme of the simulation] corresponds to inner box, here we show how to evaluate the performance of a cluster randomized trial with one specific setting of study design and probably existing specific implementation error (fidelity pattern).\nWithin each simulation experiment steps of data sampling and effect estimation, provided by function within the R-package {samplingDataCRT}, were repeated. For explanation see [Detailed statistical information]. After repeating the steps of the simulation the obtained effect estimates can be evaluated for the performance of the model. The provided function performanceMeas() of the R-package {fidelitysim} calculates the following performance measures of a simulation:\n\nBias: mean deviation of the estimates from the true value of the parameter of interest (intervention effect) is an indicator of accuracy\nCoverage: measurement used to control the Type I error rate for testing the null hypothesis (H0) of no effect\nPower: proportion of simulation samples in which the H0 of no effect is rejected at a significance level of \\(\\alpha\\) when H0 is false (is related to the empirical Type II error rate).\n\nTo simplify the process of the whole simulation experiment the R-function simulation() is provided within the R-package {fidelitysim}. The function includes the steps: data sampling for a specific design and existing implementation error, effect estimation, performance measures calculation. Hence, the input of the function is the specification parameter:\n\nnumber of repeats for the simulation\nchosen design (including study design, number of cluster, time points and individuals per cluster)\nmodel parameters (effect, variances, …)\ntwo design matrices which indicates whether deviation from perfect situations are assumed or not\n\nand the output are:\n\neffect estimates\nperformance measures\n\nThe usage is shown here for a parallel design trail, where the difference of the method application regarding the parameter setting for other design is explained. Be sure necessary packages are loaded:\n\n# load necessary packages\nlibrary(fidelitysim)\nlibrary(samplingDataCRT)\n#library(ggplot2)\n\nOne setting includes the specification of :\n\nStudy design\nIndication if there are deviations from perfect situations or not\nModel parameter\nIterations of the simulation\n\nand finally,\n\nthe Simulation experiment can be performed.\n\n\n2.1.1 Study design\nBased on the study setup, the following parameters for the study design need to be defined:\n\nNo. of clusters (e.g hospitals)\nNo. of individuals per cluster (and time point) as the cluster size\nNo. of time points the cluster were followed\nDesign type controls if individuals will be fowllowed over time (cross-sectional or longitudinal): cross-sectional type, which indicates trials where individuals within the cluster can change over time points\n\nA design matrix according the study design has to be determined by the function designMatrix(). Here, two arguments are specific for the different types of studies. If the design argument is set ‘parallel’, then the parameter nSW indicates here the number of clusters are being control group. If choosing design = \"SWD\" (which is also set by default), the he parameter nSW indicates here the number of cluster switches per time point from control to intervention group.\nThen we determine the corresponding design matrix for a parallel cluster randomized study with:\n\n6 cluster with a\ncluster size of 10 measured at\n7 time points, where\n3 clusters in each, the control as well as in the intervention group, are included\n\nas follows:\n\n## Design matrix ##\n\nI <- 6 # number of clusters\nJ <- 10 # number of individuals per cluster (used later in simulation-step)\nK <- 7 # number of time points\nSw <- 1 # number of cluster switches per time point can be manually set\n\n# design matrix for parallel design\n(designMat_prll <- designMatrix(nC = I, nT = K, nSw = round(I / 2), design = \"parallel\"))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    0    0    0    0    0    0\n[2,]    0    0    0    0    0    0    0\n[3,]    0    0    0    0    0    0    0\n[4,]    1    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1    1\n[6,]    1    1    1    1    1    1    1\n\n\n\n\n2.1.2 Indication if there are deviations from perfect situations or not\nFurther, in the function for the simulation by specifying a second design matrix X.A, we can indicate if there are deviations from the perfect situation present or not. Since we simulation perfect situation with no deviation, both arguments for the design matrices X and X.A are the same within the latter used R-function simulation() (see Simulation experiment). If deviations from perfect situation should be simulated, a second design matrix to which indicates the pattern of fidelity according to this study design has to be provided as well.\nTo consider the deviation from perfect implementation of an intervention (100% fidelity) we add fractional values to estimate the degree of the deviation and its effect on the study effects. Therefor 3 functions in within the R-package {fidelitysim} can be used to specify several fidelity patterns. For explanation of all kind of fidelity patters see [Determine different fidelity patterns]. The conducted fidelity patterns can then be pushed to the design matrix with the R-package {samplingDataCRT}, see for more explanation [Fidelity patterns].\nUsing the same parallel design trial example and assume a linear increase of fidelity from 40% to 80% from time point 1 to the end of trial (time point K) 3 arguments are specified:\n\n### Fidelity parameters ###\n\n# Fidelity at the begin\nFid.T1 <- 0.4\n# Fidelity at the end\nFid.End <- 0.8\n\n# slope for linear function\nm <- (Fid.T1 - Fid.End) / (1 - (K - 1))\n\n\n# model linear increase\nres.lin <- find.Fidelity.linear(time.points = K, Fid.End, Fid.T1)\n\nWhich is then supplied to create a design matrix that reflects the deviation from perfect implementation by fractional values for each time point and cluster (find the other two functions for slow and fast increase here [Determine different fidelity patterns]):\n\n# design matrix of a linear fidelity pattern\n(fidelMat_prll <- implemMatrix.parallel(\n  nC = I, nT = K, nSw = round(I / 2),\n  pattern = res.lin[, \"Fidelity.Prozent\"] / 100\n))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[2,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[3,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[4,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[5,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[6,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n\n\nThis matrix reflecting implementation error is then used in the simulation as a reference matrix (note the difference in arguments X = designMat_prll and X.A = fidelMat_prll within the latter used R-function simulation() in section Simulation experiment, which did not differ in the perfect simulation).\n\n\n2.1.3 Model parameter\nData for a cluster randomized trial is sampled from a model provided by the package {samplingDataCRT}. Therefore, and in addition to the design parameters, we have to define the following model parameters as well:\n\nbaseline mean of the outcome of interest (e.g. mean quality of life score) of 10\nintervention effect (the change of scores after intervention) of 1\nkind of time trend (effect of each time point during followed time points)\na between clusters and error variance regrding the outcome of interest that results in an inter-cluster correlation coefficient (ICC)\n\nDefine an hypothetical trial with:\n\nbaseline mean of the outcome of interest of 10\nintervention effect of 1\nno time trend\na between clusters and error variance that results in an ICC of 0.001\n\nas follows:\n\n## Model parameter ##\n\nmu.0 <- 10 # Baseline mean of the outcome of interest\ntheta <- 1 # Intervention effect\nbetas <- rep(0, K - 1) # no time trend, but could be included\n\n# variability within or error variance (H&H sigma)\nsigma.1 <- 2 \n# variability within clusters, if longitudina data\nsigma.2 <- NULL \n# between clusters variability (H&H tau)\nsigma.3 <- sigma.1 * sqrt(0.001 / (1 - 0.001)) \n\n# resulting ICC\n(ICC <- sigma.3^2 / (sigma.3^2 + sigma.1^2))\n\n[1] 0.001\n\n\nChoosing a longitudinal instead of a cross-sectional design for the study demand the specification of a third variance (see for more detail into [Sampling data of a cluster randomized trial with a given design]).\n\nDIANA - can we say to recommend these parameters as default values? what does mu.0 mean? How do I (non-statistician) know which values to choose? From a practical point of view I would expect to have a comment on this.\n\n\n\n2.1.4 Iterations of the simulation\nIn addition to the parameters set above, we need to define the number of iterations for the simulation. Its a number how often the sampling and estimation should be repeated to finally calculate the performance measures. The literature recommends between 10,000 and 100,000 repeats for valid results, but this comes at a time cost. To simplify this, we use n = 1,000 here.\n\n## Number of repeats within the simulation ##\nanzSim <- 100\n\n\n\n2.1.5 Simulation experiment\nSince we set all necessary arguments for the usage of the provided simulation function:\n\nStudy design\nModel parameter\nIndication if there are deviations from perfect situations or not\nIterations of the simulation\n\nwe can start the simulation by using the provided function simulation in package {fidelitysim} as follows:\n\n\n\n\n# linear increase of fidelity\nres.Simu.parallel.lin <- simulation(\n  anzSim = anzSim, #Simulation parameter\n  type = \"cross-sec\", K = K, J = J, I = I, #design paramter\n  sigma.1 = sigma.1, sigma.3 = sigma.3,\n  mu.0 = mu.0, theta = theta, betas = betas, #model parameters\n  X = designMat_prll, X.A = fidelMat_prll #design matrices\n)\n\n\nend_time <- Sys.time()\ntime.sim <- round(as.numeric((end_time - start_time), units = \"mins\"),2)\n\nRepeating the simulation 100 times for this design a computational time of 0.38 min is needed.\nThe output of the simulation provides a total of n =22 results, among the following performance parameters (see also Introduction of this Chapter):\n\nBias\nCoverage\nPower\n\nHence, the mean estimate of the intervention effect from all iterations and the power of the design can be accessed like this:\n\n# mean estimated intervention effect\nres.Simu.parallel.lin[\"intervention Mean .\"]\n\nintervention Mean . \n          0.6168129 \n\n# estimated power\n(res.Simu.parallel.lin[\"Power.Intervention\"])\n\nPower.Intervention \n               0.7 \n\n\n\n\nPower.Intervention \n               0.7 \n\n\nWe obtain a power of 0.7 to detect an intervention effect of 1 within an parallel study with 6 clusters followed 7 time points and a cluster size of 10 when an linear increase of the fidelity from 0.4 % to 0.8 is achieved after implementation of the intervention until end of the study."
  },
  {
    "objectID": "simulation-step-by-step.html#comparison-of-several-fidelity-patterns-for-a-parallel-design",
    "href": "simulation-step-by-step.html#comparison-of-several-fidelity-patterns-for-a-parallel-design",
    "title": "2  Step-by-step simulation",
    "section": "2.2 Comparison of several Fidelity patterns for a parallel design",
    "text": "2.2 Comparison of several Fidelity patterns for a parallel design\nSee again also for fidelity patterns conduction in [Fidelity patterns]. To compare the effect of different degrees of increasing fidelity after implementation against perfect trials, a repetition the simulation experiment for different degrees of fidelity increase but same settings has to be conducted.\nWe take again the example from above: cross-sectional parallel trial with ten clusters (5 of them getting the intervention, 5 of them not), 7 time points and ten individuals within each cluster and time point. We also assume a fidelity of 0.4 at the beginning and 0.8 at the end of trial for the intervention group. Here , we investigate on total 7 different fidelity pattern increases, 3 fast increases, 1 linear and 3 slow increases for this design setting.\n\n### several Slopes indicating the degree of increase ###\nslope.seq<-round(exp(1)^(seq(-2,2,2)),2)\nnr.sl<-length(slope.seq)\n\n\nstart_time <- Sys.time()\n\nAt first, perfect situation simulation (no deviation fro 100% implementation).\n\n################################\n# perfect implementation\n# no individual or cluster miss\n################################\n\n#design matrix of perfect situation\nX<-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=round(I/2), design=\"parallel\")\nres<-fidelitysim::simulation(\n                  anzSim=anzSim, #Simulation parameter\n                  type=\"cross-sec\", K=K,J=J,I=I, #design paramter\n                   sigma.1=sigma.1,sigma.3=sigma.3, #model parameters\n                   mu.0=mu.0, theta=theta,betas=betas,\n                   X=X, X.A=X #design matrices\n                  )\nres<-as.data.frame(t(res))\n\n\n\n\n\n\n\nNext for several slow increase (reflected by an exponential function):\n\n###all the other patterns\nres.Simu<-data.frame()\n\n#exponential increase\nfor(sl in 1:nr.sl){#for each slope\n    \n   #Fidelity pattern\n    res.exp<-fidelitysim::find.Fidelity.exp(time.points=K, \n                               Fid.End, Fid.T1, \n                               par.slope=slope.seq[sl])\n    #new design matrix\n    A1.exp <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                               pattern=res.exp[,\"Fidelity.Prozent\"]/100)\n     #simulation experiment  \n    res<-fidelitysim::simulation(anzSim=anzSim,\n                    type=\"cross-sec\",  K=K,J=J,I=I,\n                    sigma.1=sigma.1,sigma.3=sigma.3,\n                    mu.0=mu.0, theta=theta,betas=betas,\n                    X=X, X.A=A1.exp\n                    )\n    res<-as.data.frame(t(res))\n    #save results\n    res.Simu<-rbind(res.Simu,\n                   data.frame( res, \n                      D=\"exp\", slope=slope.seq[sl], sort=2+nr.sl+(nr.sl-sl+1), Fid.Begin=Fid.T1, Fid.END=Fid.End)\n    )\n\n}\n\n\n\n\nFor several fast increase (reflected by a logarithmic function):\n\n###all the other patterns\nres.Simu<-data.frame()\n\n#logistic increase\nfor(sl in 1:nr.sl){#for each slope\n    #Fidelity pattern\n    res.log<-fidelitysim::find.Fidelity.log(time.points=K, \n                               Fid.End, Fid.T1, \n                               par.slope=slope.seq[sl])\n    #new design matrix\n    A1.log <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                                   pattern=res.log[,\"Fidelity.Prozent\"]/100)\n    #simulation experiment\n    res<-fidelitysim::simulation(anzSim=anzSim,\n                    type=\"cross-sec\", K=K,J=J,I=I,\n                    sigma.1=sigma.1,sigma.3=sigma.3,\n                    mu.0=mu.0, theta=theta,betas=betas,\n                    X=X, X.A=A1.log)\n    res<-as.data.frame(t(res))\n    #save results\n    res.Simu<-rbind(res.Simu,\n                   data.frame( res, \n                      D=\"log\", slope=slope.seq[sl], sort=1+sl, Fid.Begin=Fid.T1, Fid.END=Fid.End)\n    )\n  }\n\n\n\n\nFor linear increase:\n\n##linear increase\nm<-(Fid.T1-Fid.End)/(1-(K-1))\n#Fidelity pattern\nres.lin<-fidelitysim::find.Fidelity.linear(time.points=K, Fid.End, Fid.T1)\n#ne design matrix\nA1.lin <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                               pattern=res.lin[,\"Fidelity.Prozent\"]/100)\n#simulation experiment\nres<-fidelitysim::simulation(anzSim=anzSim,\n                type=\"cross-sec\", K=K,J=J,I=I,\n                sigma.1=sigma.1,sigma.3=sigma.3,\n                mu.0=mu.0, theta=theta,betas=betas,\n                X=X, X.A=A1.lin)\nres<-as.data.frame(t(res))\n\n\n\n\n\n\n\nNeeds 28 minutes time for simulation each scenario 1000 times.\n\n\n\n\n\n\n\nThe figure ?fig-Sim summarize the results of the several simulations for different fidelity patterns regarding power of the study.\n{fig-Sim, width=6000}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fidelity in Hybrid Implementation Trials: Technical Guidance for Implementation Researchers",
    "section": "",
    "text": "This online tutorial serves as a hands-on guide for researchers to replicate the simulation described in\n[our paper].\nThis supplementary material was designed with regard to support applied researchers (not statisticians) to adapt the simulation with required parameters for their own study. Consequently, the content is split in the following chapters:\n\nChapter 1 gives an overview of the technical requirements\nChapter 2 describes step-by-step how to conduct the simulation for a specific research study, based on parallel or stepped wedge CRTs, furthermore show the comparison of several fidelity patterns\nChapter 3 optionally provides additional statistical information, but does not need to be consulted to be able to run the simulation\n\n\n\nIf you find this work helpful, please cite both the online tutorial and the paper by the reference of the original paper as in:\n[our paper]"
  },
  {
    "objectID": "additional-statistical-info.html",
    "href": "additional-statistical-info.html",
    "title": "3  Detailed statistical information",
    "section": "",
    "text": "This chapter offers additional statistical information."
=======
    "text": "2.1 Simulation experiment for one setting\nAccording the [Workflow diagramme of the simulation] corresponds to inner box, here we show how to evaluate the performance of a cluster randomized trial with one specific setting of study design and probably existing specific implementation error (fidelity pattern).\nWithin each simulation experiment steps of data sampling and effect estimation, provided by function within the R-package {samplingDataCRT}, were repeated. For explanation see [Detailed statistical information]. After repeating the steps of the simulation the obtained effect estimates can be evaluated for the performance of the model. The provided function performanceMeas() of the R-package {fidelitysim} calculates the following performance measures of a simulation:\n\nBias: mean deviation of the estimates from the true value of the parameter of interest (intervention effect) is an indicator of accuracy\nCoverage: measurement used to control the Type I error rate for testing the null hypothesis (H0) of no effect\nPower: proportion of simulation samples in which the H0 of no effect is rejected at a significance level of \\(\\alpha\\) when H0 is false (is related to the empirical Type II error rate).\n\nTo simplify the process of the whole simulation experiment the R-function simulation() is provided within the R-package {fidelitysim}. The function includes the steps: data sampling for a specific design and existing implementation error, effect estimation, performance measures calculation. Hence, the input of the function is the specification parameter:\n\nnumber of repeats for the simulation\nchosen design (including study design, number of cluster, time points and individuals per cluster)\nmodel parameters (effect, variances, …)\ntwo design matrices which indicates whether deviation from perfect situations are assumed or not\n\nand the output are:\n\neffect estimates\nperformance measures\n\nThe usage is shown here for a parallel design trail, where the difference of the method application regarding the parameter setting for other design is explained. Be sure necessary packages are loaded:\n\n# load necessary packages\nlibrary(fidelitysim)\nlibrary(samplingDataCRT)\n#library(ggplot2)\n\nOne setting includes the specification of :\n\nStudy design\nIndication if there are deviations from perfect situations or not\nModel parameter\nIterations of the simulation\n\nand finally,\n\nthe Simulation experiment can be performed.\n\n\n2.1.1 Study design\nBased on the study setup, the following parameters for the study design need to be defined:\n\nNo. of clusters (e.g hospitals)\nNo. of individuals per cluster (and time point) as the cluster size\nNo. of time points the cluster were followed\nDesign type controls if individuals will be fowllowed over time (cross-sectional or longitudinal): cross-sectional type, which indicates trials where individuals within the cluster can change over time points\n\nA design matrix according the study design has to be determined by the function designMatrix(). Here, two arguments are specific for the different types of studies. If the design argument is set ‘parallel’, then the parameter nSW indicates here the number of clusters are being control group. If choosing design = \"SWD\" (which is also set by default), the he parameter nSW indicates here the number of cluster switches per time point from control to intervention group.\nThen we determine the corresponding design matrix for a parallel cluster randomized study with:\n\n6 cluster with a\ncluster size of 10 measured at\n7 time points, where\n3 clusters in each, the control as well as in the intervention group, are included\n\nas follows:\n\n## Design matrix ##\n\nI <- 6 # number of clusters\nJ <- 10 # number of individuals per cluster (used later in simulation-step)\nK <- 7 # number of time points\nSw <- 1 # number of cluster switches per time point can be manually set\n\n# design matrix for parallel design\n(designMat_prll <- designMatrix(nC = I, nT = K, nSw = round(I / 2), design = \"parallel\"))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    0    0    0    0    0    0\n[2,]    0    0    0    0    0    0    0\n[3,]    0    0    0    0    0    0    0\n[4,]    1    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1    1\n[6,]    1    1    1    1    1    1    1\n\n\n\n\n2.1.2 Indication if there are deviations from perfect situations or not\nFurther, in the function for the simulation by specifying a second design matrix X.A, we can indicate if there are deviations from the perfect situation present or not. Since we simulation perfect situation with no deviation, both arguments for the design matrices X and X.A are the same within the latter used R-function simulation() (see Simulation experiment). If deviations from perfect situation should be simulated, a second design matrix to which indicates the pattern of fidelity according to this study design has to be provided as well.\nTo consider the deviation from perfect implementation of an intervention (100% fidelity) we add fractional values to estimate the degree of the deviation and its effect on the study effects. Therefor 3 functions in within the R-package {fidelitysim} can be used to specify several fidelity patterns. For explanation of all kind of fidelity patters see [Determine different fidelity patterns]. The conducted fidelity patterns can then be pushed to the design matrix with the R-package {samplingDataCRT}, see for more explanation [Fidelity patterns].\nUsing the same parallel design trial example and assume a linear increase of fidelity from 40% to 80% from time point 1 to the end of trial (time point K) 3 arguments are specified:\n\n### Fidelity parameters ###\n\n# Fidelity at the begin\nFid.T1 <- 0.4\n# Fidelity at the end\nFid.End <- 0.8\n\n# slope for linear function\nm <- (Fid.T1 - Fid.End) / (1 - (K - 1))\n\n\n# model linear increase\nres.lin <- find.Fidelity.linear(time.points = K, Fid.End, Fid.T1)\n\nWhich is then supplied to create a design matrix that reflects the deviation from perfect implementation by fractional values for each time point and cluster (find the other two functions for slow and fast increase here [Determine different fidelity patterns]):\n\n# design matrix of a linear fidelity pattern\n(fidelMat_prll <- implemMatrix.parallel(\n  nC = I, nT = K, nSw = round(I / 2),\n  pattern = res.lin[, \"Fidelity.Prozent\"] / 100\n))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[2,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[3,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[4,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[5,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[6,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n\n\nThis matrix reflecting implementation error is then used in the simulation as a reference matrix (note the difference in arguments X = designMat_prll and X.A = fidelMat_prll within the latter used R-function simulation() in section Simulation experiment, which did not differ in the perfect simulation).\n\n\n2.1.3 Model parameter\nData for a cluster randomized trial is sampled from a model provided by the package {samplingDataCRT}. Therefore, and in addition to the design parameters, we have to define the following model parameters as well:\n\nbaseline mean of the outcome of interest (e.g. mean quality of life score) of 10\nintervention effect (the change of scores after intervention) of 1\nkind of time trend (effect of each time point during followed time points)\na between clusters and error variance regrding the outcome of interest that results in an inter-cluster correlation coefficient (ICC)\n\nDefine an hypothetical trial with:\n\nbaseline mean of the outcome of interest of 10\nintervention effect of 1\nno time trend\na between clusters and error variance that results in an ICC of 0.001\n\nas follows:\n\n## Model parameter ##\n\nmu.0 <- 10 # Baseline mean of the outcome of interest\ntheta <- 1 # Intervention effect\nbetas <- rep(0, K - 1) # no time trend, but could be included\n\n# variability within or error variance (H&H sigma)\nsigma.1 <- 2 \n# variability within clusters, if longitudina data\nsigma.2 <- NULL \n# between clusters variability (H&H tau)\nsigma.3 <- sigma.1 * sqrt(0.001 / (1 - 0.001)) \n\n# resulting ICC\n(ICC <- sigma.3^2 / (sigma.3^2 + sigma.1^2))\n\n[1] 0.001\n\n\nChoosing a longitudinal instead of a cross-sectional design for the study demand the specification of a third variance (see for more detail into [Sampling data of a cluster randomized trial with a given design]).\n\nDIANA - can we say to recommend these parameters as default values? what does mu.0 mean? How do I (non-statistician) know which values to choose? From a practical point of view I would expect to have a comment on this.\n\n\n\n2.1.4 Iterations of the simulation\nIn addition to the parameters set above, we need to define the number of iterations for the simulation. Its a number how often the sampling and estimation should be repeated to finally calculate the performance measures. The literature recommends between 10,000 and 100,000 repeats for valid results, but this comes at a time cost. To simplify this, we use n = 1,000 here.\n\n## Number of repeats within the simulation ##\nanzSim <- 100\n\n\n\n2.1.5 Simulation experiment\nSince we set all necessary arguments for the usage of the provided simulation function:\n\nStudy design\nModel parameter\nIndication if there are deviations from perfect situations or not\nIterations of the simulation\n\nwe can start the simulation by using the provided function simulation in package {fidelitysim} as follows:\n\n\n\n\n# linear increase of fidelity\nres.Simu.parallel.lin <- simulation(\n  anzSim = anzSim, #Simulation parameter\n  type = \"cross-sec\", K = K, J = J, I = I, #design paramter\n  sigma.1 = sigma.1, sigma.3 = sigma.3,\n  mu.0 = mu.0, theta = theta, betas = betas, #model parameters\n  X = designMat_prll, X.A = fidelMat_prll #design matrices\n)\n\n\nend_time <- Sys.time()\ntime.sim <- round(as.numeric((end_time - start_time), units = \"mins\"),2)\n\nRepeating the simulation 100 times for this design a computational time of 0.23 min is needed.\nThe output of the simulation provides a total of n =22 results, among the following performance parameters (see also Introduction of this Chapter):\n\nBias\nCoverage\nPower\n\nHence, the mean estimate of the intervention effect from all iterations and the power of the design can be accessed like this:\n\n# mean estimated intervention effect\nres.Simu.parallel.lin[\"intervention Mean .\"]\n\nintervention Mean . \n          0.6119336 \n\n# estimated power\n(res.Simu.parallel.lin[\"Power.Intervention\"])\n\nPower.Intervention \n              0.75 \n\n\n\n\nPower.Intervention \n              0.75 \n\n\nWe obtain a power of 0.75 to detect an intervention effect of 1 within an parallel study with 6 clusters followed 7 time points and a cluster size of 10 when an linear increase of the fidelity from 0.4 % to 0.8 is achieved after implementation of the intervention until end of the study."
  },
  {
    "objectID": "simulation-step-by-step.html#comparison-of-several-fidelity-patterns-for-a-parallel-design",
    "href": "simulation-step-by-step.html#comparison-of-several-fidelity-patterns-for-a-parallel-design",
    "title": "2  Step-by-step simulation",
    "section": "2.2 Comparison of several Fidelity patterns for a parallel design",
    "text": "2.2 Comparison of several Fidelity patterns for a parallel design\nSee again also for fidelity patterns conduction in [Fidelity patterns]. To compare the effect of different degrees of increasing fidelity after implementation against perfect trials, a repetition the simulation experiment for different degrees of fidelity increase but same settings has to be conducted.\nWe take again the example from above: cross-sectional parallel trial with ten clusters (5 of them getting the intervention, 5 of them not), 7 time points and ten individuals within each cluster and time point. We also assume a fidelity of 0.4 at the beginning and 0.8 at the end of trial for the intervention group. Here , we investigate on total 7 different fidelity pattern increases, 3 fast increases, 1 linear and 3 slow increases for this design setting.\n\n### several Slopes indicating the degree of increase ###\nslope.seq<-round(exp(1)^(seq(-2,2,2)),2)\nnr.sl<-length(slope.seq)\n\n\nstart_time <- Sys.time()\n\nAt first, perfect situation simulation (no deviation fro 100% implementation).\n\n################################\n# perfect implementation\n# no individual or cluster miss\n################################\n\n#design matrix of perfect situation\nX<-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=round(I/2), design=\"parallel\")\nres<-fidelitysim::simulation(\n                  anzSim=anzSim, #Simulation parameter\n                  type=\"cross-sec\", K=K,J=J,I=I, #design paramter\n                   sigma.1=sigma.1,sigma.3=sigma.3, #model parameters\n                   mu.0=mu.0, theta=theta,betas=betas,\n                   X=X, X.A=X #design matrices\n                  )\nres<-as.data.frame(t(res))\n\n\n\n\n\n\n\nNext for several slow increase (reflected by an exponential function):\n\n###all the other patterns\nres.Simu<-data.frame()\n\n#exponential increase\nfor(sl in 1:nr.sl){#for each slope\n    \n   #Fidelity pattern\n    res.exp<-fidelitysim::find.Fidelity.exp(time.points=K, \n                               Fid.End, Fid.T1, \n                               par.slope=slope.seq[sl])\n    #new design matrix\n    A1.exp <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                               pattern=res.exp[,\"Fidelity.Prozent\"]/100)\n     #simulation experiment  \n    res<-fidelitysim::simulation(anzSim=anzSim,\n                    type=\"cross-sec\",  K=K,J=J,I=I,\n                    sigma.1=sigma.1,sigma.3=sigma.3,\n                    mu.0=mu.0, theta=theta,betas=betas,\n                    X=X, X.A=A1.exp\n                    )\n    res<-as.data.frame(t(res))\n    #save results\n    res.Simu<-rbind(res.Simu,\n                   data.frame( res, \n                      D=\"exp\", slope=slope.seq[sl], sort=2+nr.sl+(nr.sl-sl+1), Fid.Begin=Fid.T1, Fid.END=Fid.End)\n    )\n\n}\n\n\n\n\nFor several fast increase (reflected by a logarithmic function):\n\n###all the other patterns\nres.Simu<-data.frame()\n\n#logistic increase\nfor(sl in 1:nr.sl){#for each slope\n    #Fidelity pattern\n    res.log<-fidelitysim::find.Fidelity.log(time.points=K, \n                               Fid.End, Fid.T1, \n                               par.slope=slope.seq[sl])\n    #new design matrix\n    A1.log <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                                   pattern=res.log[,\"Fidelity.Prozent\"]/100)\n    #simulation experiment\n    res<-fidelitysim::simulation(anzSim=anzSim,\n                    type=\"cross-sec\", K=K,J=J,I=I,\n                    sigma.1=sigma.1,sigma.3=sigma.3,\n                    mu.0=mu.0, theta=theta,betas=betas,\n                    X=X, X.A=A1.log)\n    res<-as.data.frame(t(res))\n    #save results\n    res.Simu<-rbind(res.Simu,\n                   data.frame( res, \n                      D=\"log\", slope=slope.seq[sl], sort=1+sl, Fid.Begin=Fid.T1, Fid.END=Fid.End)\n    )\n  }\n\n\n\n\nFor linear increase:\n\n##linear increase\nm<-(Fid.T1-Fid.End)/(1-(K-1))\n#Fidelity pattern\nres.lin<-fidelitysim::find.Fidelity.linear(time.points=K, Fid.End, Fid.T1)\n#ne design matrix\nA1.lin <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                               pattern=res.lin[,\"Fidelity.Prozent\"]/100)\n#simulation experiment\nres<-fidelitysim::simulation(anzSim=anzSim,\n                type=\"cross-sec\", K=K,J=J,I=I,\n                sigma.1=sigma.1,sigma.3=sigma.3,\n                mu.0=mu.0, theta=theta,betas=betas,\n                X=X, X.A=A1.lin)\nres<-as.data.frame(t(res))\n\n\n\n\n\n\n\nNeeds 28 minutes time for simulation each scenario 1000 times.\n\n\n\n\n\n\n\nThe figure Figure 2.1 summarize the results of the several simulations for different fidelity patterns regarding power of the study.\n\n\n\nFigure 2.1: Results"
>>>>>>> 30fa3fcd4e39a7b91e7df9d2ff5d0e34b1aad3fa
  },
  {
    "objectID": "additional-statistical-info.html#explanation-of-simulation-experiment-and-provided-corresponding-function",
    "href": "additional-statistical-info.html#explanation-of-simulation-experiment-and-provided-corresponding-function",
    "title": "3  Detailed statistical information",
    "section": "3.1 Explanation of simulation experiment and provided corresponding function",
<<<<<<< HEAD
    "text": "3.1 Explanation of simulation experiment and provided corresponding function\nFor a simulation experiment like in [Tutorial] it is not necessary to understand the whole statistical modeling background, which is figured out here.\nEach simulation step includes three necessary steps:\n\nDetermining the design matrix regarding the specified design\nSampling data\nEffect estimation from the data\n\nand will be explained with more detail in the following subsections.\nFor the first 2 steps the provided R-package {samplingDataCRT} v1.0 (Trutschel and Treutler 2017) is needed, for the last {lme4}. How to install and load see [Introduction]. The first steps is done once and the latter two are used repeatedly through one simulation experiment within each scenario setting specified in step 1.\n\n3.1.1 Determining the design matrix regarding the chosen design\nTo specify a cluster randomized study the following parameter has to be determined:\n\nNumber of clusters (e.g. hospitals, nursing homes, …) obtained through the study\nNumber of time points the clusters are followed\nCluster size refers to the number of individuals obtained within one cluster\nStudy design: parallel design or Stepped wedge design (cross-over as well possible)\nStudy type: cross-sectional if individuals could be different within the cluster between time points or longitudinal if individuals are followed over time\n\nBased on the example in the main article, we specify a hypothetical example including parameter settings for a reference setup of the simulation experiment: a cross-sectional stepped wedge cluster randomized trial with 10 nursing homes, 6 time points and 10 individuals within each nursing home and time point (see main article). All parameters can be adapted to an own practical example. The resulting reference design matrix can be create manually (by create a corresponding matrix) or by the provided R-function designMatrix().\n\n######################################################\n#using the parameter setting of Table 1 in the article\n######################################################\n\n## Design ##\n############\nK<-7 #number of time points\nI<-6 #number of cluster\nSw<-1 #number of cluster switches per time point can be manually set\nJ<-10 #Subjects =  Number of individuals per cluster\n\n#design matrix of \"SWD\" with given setting\n(X<-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=Sw))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    1    1    1    1    1    1\n[2,]    0    0    1    1    1    1    1\n[3,]    0    0    0    1    1    1    1\n[4,]    0    0    0    0    1    1    1\n[5,]    0    0    0    0    0    1    1\n[6,]    0    0    0    0    0    0    1\n\n\n\n\n3.1.2 Sampling data of a cluster randomized trial with a given design\nTo sample data for a cluster randomized trial using sampling from a multivariate normal distribution provided by the package {samplingDataCRT}, several model parameter has also be specified:\n\nBaseline mean of the outcome of interest\nIntervention effect (change/difference in mean outcome) by implementing the intervention)\nTime trend effects\nVariance within the multilevel data: between clusters, between individuals, within individuals which provide an estimate of the intra-cluster correlation coefficient (ICC) as an measure of dependencies within clusters.\n\nIn the example here we set the mean outcome to 10 (e.g. the mean population value of measured quality of life), the intervention effect which aimed to change quality of life of 1, and no time trends. With a given between cluster variance of sigma.3 and a error variance of sigma.1, the resulting ICC is ICC.\n\n## Model parameter ##\n####################\nmu.0<- 10           # Baseline mean of the outcome of interest\ntheta <- 1          # intervention effect\nbetas<-rep(0, K-1)  # no Time trend, but could be included\n\n# variability within or error variance (H&H sigma)\nsigma.1<-2    \n# variability within clusters, if longitudina data\nsigma.2<-NULL\n# between clusters variability (H&H tau)\nsigma.3<-sigma.1*sqrt(0.001/(1-0.001))    \n\n#resulting ICC\n(ICC<-sigma.3^2/(sigma.3^2+sigma.1^2))\n\n[1] 0.001\n\n\nTo note, by choosing longitudinal or cross-sectional design, we need to specify in the first case 3, in the second only two variances regarding using a three- instead of a two-level hierarchical experiment with the following meaning:\n\nthree-level design (longitudinal data):\n\nbetween clusters variability\nwithin cluster (or between individuals) variability\nwithin individuals (or error) variability\n\ntwo-level design (cross-sectional data):\n\nbetween clusters variability [\\(\\sigma\\) put this reference here Hussey and Hughes 2007]\nwithin cluster (or error) variability [ \\(\\tau\\) put this reference here Hussey and Hughes 2007]\n\n\nA complete data set for a special design with a given setup can be sampled by the given function R-function {sampleData()}. Therefore,the complete data design matrix and the covariance-variance matrix for the data given the design are also needed to be specified, which is provided by the functions R-function {completeDataDesignMatrix()} and R-function {CovMat.Design()}. The complete data design matrix has the size of (Number of cluster x cluster size x Number of time points) rows and (Number of model parameters) columns. To sample the data from for a cluster randomized trial, it has additionally be specified, if the individuals are followed over time (longitudinal design) or not (cross-sectional design).\n\n#complete data design matrix\nD<-samplingDataCRT::completeDataDesignMatrix(J, X)\n(dim(D))\n\n[1] 420   8\n\n#covariance-variance matrix for the data given the design\nV<-samplingDataCRT::CovMat.Design(K, J, I, sigma.1=sigma.1, sigma.3=sigma.3)\ndim(V)\n\n[1] 420 420\n\n#corresponding fixed effects in linear mixed model\nparameters<-c(mu.0, betas, theta)\n\n#sample complete data given the setup\n# study design type = cross-sectional\ntype<-\"cross-sec\" \nsample.data<-samplingDataCRT::sampleData(type = type, K=K,J=J,I=I, D=D, V=V, parameters=parameters)\n\nTo validate the number of observations provided by the sampling method a summary of the data can be conducted.\n\ndim(sample.data)\n\n[1] 420   5\n\n#show the number of observations within the SWD\nxtabs(~cluster+measurement, data=sample.data)\n\n       measurement\ncluster  1  2  3  4  5  6  7\n      1 10 10 10 10 10 10 10\n      2 10 10 10 10 10 10 10\n      3 10 10 10 10 10 10 10\n      4 10 10 10 10 10 10 10\n      5 10 10 10 10 10 10 10\n      6 10 10 10 10 10 10 10\n\n\n\n\n3.1.3 Effect estimation from the data\nThe sampled data can then be analyzed by a linear mixed model with the function R-function{lmer()} of the package R-package {lme4}, hence the parameter of the model will be estimated.\n\n#analysis of the two-level data by a linear mixe model\nlme4::lmer(val~intervention+measurement + (1|cluster), data=sample.data)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: val ~ intervention + measurement + (1 | cluster)\n   Data: sample.data\nREML criterion at convergence: 1471.383\nRandom effects:\n Groups   Name        Std.Dev.\n cluster  (Intercept) 0.1068  \n Residual             1.3841  \nNumber of obs: 420, groups:  cluster, 6\nFixed Effects:\n (Intercept)  intervention  measurement2  measurement3  measurement4  \n    10.10819       1.31122       0.12387      -0.04498      -0.14178  \nmeasurement5  measurement6  measurement7  \n    -0.45845      -0.30624      -0.41988  \n\n\nThis process of sampling data and effect estimation from the data will be used repeatedly through the simulation experiment within each scenario setting."
=======
    "text": "3.1 Explanation of simulation experiment and provided corresponding function\nFor a simulation experiment like in [Tutorial] it is not necessary to understand the whole statistical modeling background, which is figured out here.\nEach simulation step includes three necessary steps:\n\nDetermining the design matrix regarding the specified design\nSampling data\nEffect estimation from the data\n\nand will be explained with more detail in the following subsections.\nFor the first 2 steps the provided R-package {samplingDataCRT} v1.0 (Trutschel and Treutler 2017) is needed, for the last {lme4}. How to install and load see [Introduction]. The first steps is done once and the latter two are used repeatedly through one simulation experiment within each scenario setting specified in step 1.\n\n3.1.1 Determining the design matrix regarding the chosen design\nTo specify a cluster randomized study the following parameter has to be determined:\n\nNumber of clusters (e.g. hospitals, nursing homes, …) obtained through the study\nNumber of time points the clusters are followed\nCluster size refers to the number of individuals obtained within one cluster\nStudy design: parallel design or Stepped wedge design (cross-over as well possible)\nStudy type: cross-sectional if individuals could be different within the cluster between time points or longitudinal if individuals are followed over time\n\nBased on the example in the main article, we specify a hypothetical example including parameter settings for a reference setup of the simulation experiment: a cross-sectional stepped wedge cluster randomized trial with 10 nursing homes, 6 time points and 10 individuals within each nursing home and time point (see main article). All parameters can be adapted to an own practical example. The resulting reference design matrix can be create manually (by create a corresponding matrix) or by the provided R-function designMatrix().\n\n######################################################\n#using the parameter setting of Table 1 in the article\n######################################################\n\n## Design ##\n############\nK<-7 #number of time points\nI<-6 #number of cluster\nSw<-1 #number of cluster switches per time point can be manually set\nJ<-10 #Subjects =  Number of individuals per cluster\n\n#design matrix of \"SWD\" with given setting\n(X<-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=Sw))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    1    1    1    1    1    1\n[2,]    0    0    1    1    1    1    1\n[3,]    0    0    0    1    1    1    1\n[4,]    0    0    0    0    1    1    1\n[5,]    0    0    0    0    0    1    1\n[6,]    0    0    0    0    0    0    1\n\n\n\n\n3.1.2 Sampling data of a cluster randomized trial with a given design\nTo sample data for a cluster randomized trial using sampling from a multivariate normal distribution provided by the package {samplingDataCRT}, several model parameter has also be specified:\n\nBaseline mean of the outcome of interest\nIntervention effect (change/difference in mean outcome) by implementing the intervention)\nTime trend effects\nVariance within the multilevel data: between clusters, between individuals, within individuals which provide an estimate of the intra-cluster correlation coefficient (ICC) as an measure of dependencies within clusters.\n\nIn the example here we set the mean outcome to 10 (e.g. the mean population value of measured quality of life), the intervention effect which aimed to change quality of life of 1, and no time trends. With a given between cluster variance of sigma.3 and a error variance of sigma.1, the resulting ICC is ICC.\n\n## Model parameter ##\n####################\nmu.0<- 10           # Baseline mean of the outcome of interest\ntheta <- 1          # intervention effect\nbetas<-rep(0, K-1)  # no Time trend, but could be included\n\n# variability within or error variance (H&H sigma)\nsigma.1<-2    \n# variability within clusters, if longitudina data\nsigma.2<-NULL\n# between clusters variability (H&H tau)\nsigma.3<-sigma.1*sqrt(0.001/(1-0.001))    \n\n#resulting ICC\n(ICC<-sigma.3^2/(sigma.3^2+sigma.1^2))\n\n[1] 0.001\n\n\nTo note, by choosing longitudinal or cross-sectional design, we need to specify in the first case 3, in the second only two variances regarding using a three- instead of a two-level hierarchical experiment with the following meaning:\n\nthree-level design (longitudinal data):\n\nbetween clusters variability\nwithin cluster (or between individuals) variability\nwithin individuals (or error) variability\n\ntwo-level design (cross-sectional data):\n\nbetween clusters variability [\\(\\sigma\\) put this reference here Hussey and Hughes 2007]\nwithin cluster (or error) variability [ \\(\\tau\\) put this reference here Hussey and Hughes 2007]\n\n\nA complete data set for a special design with a given setup can be sampled by the given function R-function {sampleData()}. Therefore,the complete data design matrix and the covariance-variance matrix for the data given the design are also needed to be specified, which is provided by the functions R-function {completeDataDesignMatrix()} and R-function {CovMat.Design()}. The complete data design matrix has the size of (Number of cluster x cluster size x Number of time points) rows and (Number of model parameters) columns. To sample the data from for a cluster randomized trial, it has additionally be specified, if the individuals are followed over time (longitudinal design) or not (cross-sectional design).\n\n#complete data design matrix\nD<-samplingDataCRT::completeDataDesignMatrix(J, X)\n(dim(D))\n\n[1] 420   8\n\n#covariance-variance matrix for the data given the design\nV<-samplingDataCRT::CovMat.Design(K, J, I, sigma.1=sigma.1, sigma.3=sigma.3)\ndim(V)\n\n[1] 420 420\n\n#corresponding fixed effects in linear mixed model\nparameters<-c(mu.0, betas, theta)\n\n#sample complete data given the setup\n# study design type = cross-sectional\ntype<-\"cross-sec\" \nsample.data<-samplingDataCRT::sampleData(type = type, K=K,J=J,I=I, D=D, V=V, parameters=parameters)\n\nTo validate the number of observations provided by the sampling method a summary of the data can be conducted.\n\ndim(sample.data)\n\n[1] 420   5\n\n#show the number of observations within the SWD\nxtabs(~cluster+measurement, data=sample.data)\n\n       measurement\ncluster  1  2  3  4  5  6  7\n      1 10 10 10 10 10 10 10\n      2 10 10 10 10 10 10 10\n      3 10 10 10 10 10 10 10\n      4 10 10 10 10 10 10 10\n      5 10 10 10 10 10 10 10\n      6 10 10 10 10 10 10 10\n\n\n\n\n3.1.3 Effect estimation from the data\nThe sampled data can then be analyzed by a linear mixed model with the function R-function{lmer()} of the package R-package {lme4}, hence the parameter of the model will be estimated.\n\n#analysis of the two-level data by a linear mixe model\nlme4::lmer(val~intervention+measurement + (1|cluster), data=sample.data)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: val ~ intervention + measurement + (1 | cluster)\n   Data: sample.data\nREML criterion at convergence: 1484.079\nRandom effects:\n Groups   Name        Std.Dev.\n cluster  (Intercept) 0.1078  \n Residual             1.4056  \nNumber of obs: 420, groups:  cluster, 6\nFixed Effects:\n (Intercept)  intervention  measurement2  measurement3  measurement4  \n     10.0799        1.2552        0.1157       -0.1556        0.1437  \nmeasurement5  measurement6  measurement7  \n     -0.2108       -0.1667       -0.3378  \n\n\nThis process of sampling data and effect estimation from the data will be used repeatedly through the simulation experiment within each scenario setting."
>>>>>>> 30fa3fcd4e39a7b91e7df9d2ff5d0e34b1aad3fa
  },
  {
    "objectID": "additional-statistical-info.html#determine-differrent-design-matrices",
    "href": "additional-statistical-info.html#determine-differrent-design-matrices",
    "title": "3  Detailed statistical information",
    "section": "3.2 Determine differrent design matrices",
    "text": "3.2 Determine differrent design matrices\nThe function designMatrix of the R-package {samplingDataCRT} provides the design matrix of cluster randomized trials with several study designs, given the number of clusters, time points and cluster size assumed for the trial. We show here for two examples:\n\nparallel\nSWD\n\n\n3.2.1 Parallel cluster randomized trials\nWithin the function the design argument is set ‘parallel’, and the parameter nSW indicates the number of clusters are being control group.\n\n## Design paramter ##\n######################\nI <- 6 # number of clusters\nJ <- 10 # number of individuals per cluster (used later in simulation-step)\nK <- 7 # number of time points\nSw <- round(I / 2) # number of cluster within the control group\n\n# design matrix for parallel design\n(designMat_prll <- samplingDataCRT::designMatrix(nC = I, nT = K, nSw = round(I / 2), design = \"parallel\"))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    0    0    0    0    0    0\n[2,]    0    0    0    0    0    0    0\n[3,]    0    0    0    0    0    0    0\n[4,]    1    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1    1\n[6,]    1    1    1    1    1    1    1\n\n\n\n\n3.2.2 Stepped wedge cluster randomized trial\nWhereas the design parameters can be the same as in the parallel study the design matrix differs accordingly when changing the argument design = \"SWD\" (which is also set by default, so it has not to be specified). The parameter ‘nSW’ indicates here the number of cluster switches per time point from control to intervention group.\n\n## Design matrix ##\n\nI <- 6 # number of clusters\nJ <- 10 # number of individuals per cluster (used later in simulation-step)\nK <- 7 # number of time points\nSw <- 1 # number of cluster switches per time point can be manually set\n\n# design matrix of \"SWD\"\n(designMat_SWD <- samplingDataCRT::designMatrix(nC = I, nT = K, nSw = Sw, design = \"SWD\"))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    1    1    1    1    1    1\n[2,]    0    0    1    1    1    1    1\n[3,]    0    0    0    1    1    1    1\n[4,]    0    0    0    0    1    1    1\n[5,]    0    0    0    0    0    1    1\n[6,]    0    0    0    0    0    0    1"
  },
  {
    "objectID": "additional-statistical-info.html#determine-different-fidelity-patterns",
    "href": "additional-statistical-info.html#determine-different-fidelity-patterns",
    "title": "3  Detailed statistical information",
    "section": "3.3 Determine different fidelity patterns",
    "text": "3.3 Determine different fidelity patterns\nFidelity refers to the degree to which an intervention was implemented as it was prescribed or intended. We aim to include different patterns of how fidelity might increase over time to estimate the respective effects on power of the study. To describe hypothetical fidelity patterns of increasing fidelity (slow, linear, fast) different mathematical functions (i.e. logistic, linear and exponential curves) are implemented. By considering different values for the slope parameter we can cover a range of fidelity patterns. The slope parameter ranges form \\((0,\\infty)\\), where a slope parameter near to \\(0\\) indicates a increase far away from a linear (fast increase upper left corner, slow increase right bottom corner curve) and a great slope parameter near to linear (See figure Figure 3.1 ).\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n#study design\n#############\n#number of measurement\nK<-7  \n#points of time afterintervention\nT.points<-K-1\n\n#parameter Fidelity specification\n###############################\nFid.T1<-0.2\nFid.End<-1\n\n####set several slopes of increasing fidelity\n#######################################\nslope.seq<-round(exp(1)^(seq(-2,2,1)),2)\nnr.sl<-length(slope.seq)\n\n####fidelity patterns determined by several slopes within slow and fast increase\n##############################################################################\nres.plot.Patterns<-NULL\nfor(sl in slope.seq){\n res<-fidelitysim::find.Fidelity.log(time.points=T.points, Fid.End, Fid.T1, par.slope=sl)\n res<-data.frame(res, FUN=\"log\", slope=sl)\n res.plot.Patterns<-rbind(res.plot.Patterns, res)\n res<-fidelitysim::find.Fidelity.exp(time.points=T.points, Fid.End, Fid.T1, par.slope=sl)\n res<-data.frame(res, FUN=\"exp\", slope=sl)\n res.plot.Patterns<-rbind(res.plot.Patterns, res)\n      \n}\n\n#fidelity pattern for linear increase\n#####################################\nres.lin<-fidelitysim::find.Fidelity.linear(time.points=T.points, Fid.End, Fid.T1)\nres.plot.Patterns<-rbind(res.plot.Patterns, data.frame(res.lin, FUN=\"linear\", slope=1))\n\n\n\n\n\n\nFigure 3.1: Patterns of a fidelity increase (fast, linear or slow) over 6 times points\n\n\n\n\n\n\n\nFor our calculation within the simulation we use then these determined fractional values of intervention effects to define the degree of deviation from 100% implementation within the design matrix. Technically 3 functions in the R-package {fidelitysim} provides the implementation of the different patterns of fidelity. To create a corresponding design matrix using the fidelity patterns also a function is provided for each design.\n\n3.3.1 Slow increase of fidelity using exponential function\nHere we show an example how to determine the design matrix for a cluster randomized parallel design study (with same design as above) with existing implementation error, where fidelity starts with 40% after implementation and reach after a slow increase 80% at the end of the study. A great slope parameter is chosen which reflect a slow increase more closed to the linear increase.\n\n#study design\n#############\nI <- 6 # number of clusters\nJ <- 10 # number of individuals per cluster (used later in simulation-step)\nK <- 7 # number of time points\nSw<- round(I/2) # number of cluster within the control group\n\n#parameter Fidelity specification\n###############################\nFid.T1<-0.4\nFid.End<-0.8\n\n#parameter tunes the slope for the log and exp functions\nslope.seq<-5\n  \n#exponential function to determine slow increase\n(res.exp<-fidelitysim::find.Fidelity.exp(time.points=K, Fid.End, Fid.T1, par.slope=slope.seq))\n\n     time Fidelity.Prozent\n[1,]    1               40\n[2,]    2               44\n[3,]    3               49\n[4,]    4               55\n[5,]    5               62\n[6,]    6               70\n[7,]    7               80\n\n#determine correspondingdesign matrix\n(A1.exp <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=Sw, \n                                pattern=res.exp[,\"Fidelity.Prozent\"]/100))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00 0.00 0.00  0.0  0.0\n[2,]  0.0 0.00 0.00 0.00 0.00  0.0  0.0\n[3,]  0.0 0.00 0.00 0.00 0.00  0.0  0.0\n[4,]  0.4 0.44 0.49 0.55 0.62  0.7  0.8\n[5,]  0.4 0.44 0.49 0.55 0.62  0.7  0.8\n[6,]  0.4 0.44 0.49 0.55 0.62  0.7  0.8\n\n\n\n\n3.3.2 Linear increase of fidelity using linear function\nHere we show an example how to determine the design matrix for a cluster randomized parallel design study (with same design as above) with existing implementation error, where fidelity starts with 40% after implementation and reach after a linear increase 80% at the end of the study.\n\n#parameter Fidelity specification\n###############################\nFid.T1<-0.4\nFid.End<-0.8\n\n\n#slope for linear function\nm<-(Fid.T1-Fid.End)/(1-(K-1))\n#linear increase\n(res.lin<-fidelitysim::find.Fidelity.linear(time.points=K, Fid.End, Fid.T1))\n\n     time Fidelity.Prozent\n[1,]    1               40\n[2,]    2               47\n[3,]    3               53\n[4,]    4               60\n[5,]    5               67\n[6,]    6               73\n[7,]    7               80\n\n# design matrix of a learning impelementation pattern, linear\n(A1.lin <-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                                pattern=res.lin[,\"Fidelity.Prozent\"]/100))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[2,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[3,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[4,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[5,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[6,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n\n\n\n\n3.3.3 Fast increase of fidelity using logarithmic function\nHere we show an example how to determine the design matrix for a cluster randomized stepped wedge design study (with same design as above) with existing implementation error, where fidelity starts with 20% after implementation and reach after a fast increase 100% at the end of the study. A small slope parameter is chosen for determining the fidelity curve, which reflect a very fast increase.\n\nSw <- 1 # number of cluster switches per time point can be manually set\n\n#parameter Fidelity specification\n###############################\nFid.T1<-0.2\nFid.End<-1\n\n#parameter tunes the slope for the log and exp functions\nslope.seq<-0.2\n\n#logistic function to determine fast increase\n(res.log<-fidelitysim::find.Fidelity.log(time.points=K-1, Fid.End, Fid.T1, par.slope=slope.seq))\n\n     time Fidelity.Prozent\n[1,]    1               20\n[2,]    2               95\n[3,]    3               97\n[4,]    4               98\n[5,]    5               99\n[6,]    6              100\n\n(A1.log <-samplingDataCRT::implemMatrix.SWD(nC=I, nT=K, nSw=Sw, \n                                pattern=res.log[,\"Fidelity.Prozent\"]/100))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0  0.2 0.95 0.97 0.98 0.99 1.00\n[2,]    0  0.0 0.20 0.95 0.97 0.98 0.99\n[3,]    0  0.0 0.00 0.20 0.95 0.97 0.98\n[4,]    0  0.0 0.00 0.00 0.20 0.95 0.97\n[5,]    0  0.0 0.00 0.00 0.00 0.20 0.95\n[6,]    0  0.0 0.00 0.00 0.00 0.00 0.20\n\n\n\n\n\n\nTrutschel, Diana, and Hendrik Treutler. 2017. samplingDataCRT: Sampling Data Within Different Study Designs for Cluster Randomized Trials. https://CRAN.R-project.org/package=samplingDataCRT."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.\n“Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical\nSoftware 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nR Core Team. 2022. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nTrutschel, Diana, and Catherine Blatter. 2022. fidelitysim: Simulations Experiments for Cluster\nRandomized Trials Having Fidelity Patterns for Implementation Science\nResearch.\n\n\nTrutschel, Diana, and Hendrik Treutler. 2017. samplingDataCRT: Sampling Data Within Different\nStudy Designs for Cluster Randomized Trials. https://CRAN.R-project.org/package=samplingDataCRT.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data\nAnalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org."
  }
]