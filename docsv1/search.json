[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The unrecognized role of fidelity in hybrid effectiveness-implementation trials: simulation study and guidance for implementation researchers",
    "section": "",
    "text": "Preface\nThis online tutorial serves as a hands-on guide for researchers to replicate the simulation described in\n“The unrecognized role of fidelity in effectiveness-implementation hybrid trials: simulation study and guidance for implementation researchers”, by Trutschel et al. .\nThis supplementary material was designed to support applied researchers to adapt the simulation with required parameters for their own study. Consequently, the content is split in the following chapters:"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "The unrecognized role of fidelity in hybrid effectiveness-implementation trials: simulation study and guidance for implementation researchers",
    "section": "Citation",
    "text": "Citation\nIf you find this work helpful, please cite both the online tutorial and the paper by the reference of the original paper as in:\n[add citation once available]"
  },
  {
    "objectID": "intro.html#required-r-packages",
    "href": "intro.html#required-r-packages",
    "title": "1  Introduction",
    "section": "Required R packages",
    "text": "Required R packages\nThe following R packages are needed to run the simulation:\n\n{fidelitysim} (Trutschel and Blatter 2022) - holds packaged code for the simulation experiment\n\nIt uses and builds upon:\n\n{samplingDataCRT} v1.0 (Trutschel and Treutler 2017) - for sampling data matrices\n{lme4} (Bates et al. 2015) - for linear model estimation\n{ggplot2} (Wickham 2016) - for visualizing the results\n\nYou can install the necessary packages by:\n\n# to install {fidelitysim} we need the {remotes}-package\ninstall.packages(\"remotes\")\n\n# then install {fidelitysim} from GitHub\nremotes::install_github(\"INS-Basel/fidelitysim\")\n\nThe other packages are installed from CRAN:\n\n# install packages from CRAN\ninstall.packages(c(\"samplingDataCRT\", \"lme4\", \"ggplot2\"))\n\nConsequently, to start the calculation the package needs to be loaded by:\n\nlibrary(fidelitysim)"
  },
  {
    "objectID": "intro.html#other-considerations",
    "href": "intro.html#other-considerations",
    "title": "1  Introduction",
    "section": "Other considerations",
    "text": "Other considerations\nThe local simulation can - depending on the number of clusters and the computational power - take up to 10-12 hours when the commenly recommended number of iterations of 10,000 is used. We suggest the user to start own simulations with a small number and than increase, when it is clear the code is running.\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nR Core Team. 2022. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nTrutschel, Diana, and Catherine Blatter. 2022. fidelitysim: Simulations Experiments for Cluster Randomized Trials Having Fidelity Patterns for Implementation Science Research.\n\n\nTrutschel, Diana, and Hendrik Treutler. 2017. samplingDataCRT: Sampling Data Within Different Study Designs for Cluster Randomized Trials. https://CRAN.R-project.org/package=samplingDataCRT.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org."
  },
  {
    "objectID": "simulation-step-by-step.html#sec-simintro",
    "href": "simulation-step-by-step.html#sec-simintro",
    "title": "2  Step-by-step simulation",
    "section": "Simulation experiment for one setting",
    "text": "Simulation experiment for one setting\nAccording to the inner frame of Figure 2.1, several specifications have to be made to evaluate the performance of a chosen design and fidelity pattern.\nWithin each simulation-experiment, the steps data sampling and effect estimation will be repeated (further explanation see Chapter 3.) To simplify the process of the whole simulation-experiment, we packaged the code into the R package {fidelitysim}.\nThe function fidelitysim::simulation() includes the steps: data sampling for a specific design and existing implementation error, effect estimation, performance measures calculation and the following parameters are needed as arguments to the function:\n\nnumber of repeats for the simulation\nchosen design (including study design, number of cluster, time points and individuals per cluster)\nmodel parameters (effect, variances, …)\ntwo design matrices which indicates whether deviation from perfect situations are assumed or not\n\nThe outputs of the function are:\n\neffect estimates\nperformance measures\n\nAfter repeating the steps of the simulation the obtained effect estimates can be evaluated for the performance of the model. The following performance measures of a simulation are provided:\n\nBias: mean deviation of the estimates from the true value of the parameter of interest (intervention effect) is an indicator of accuracy\nCoverage: measurement used to control the Type I error rate for testing the null hypothesis (H0) of no effect\nPower: proportion of simulation samples in which the H0 of no effect is rejected at a significance level of \\(\\alpha\\) when H0 is false (is related to the empirical Type II error rate).\n\nIn the following, we will show an example of a whole simulation experiment for a parallel cluster randomized trial. Further we will point out necessary adaptions for stepped-wedge designs (regarding the parameter setting).\nFirst, make sure that necessary packages are loaded (and to obtain the same results) indicate a seed for the simulation:\n\n# load necessary packages\nlibrary(fidelitysim)\nlibrary(samplingDataCRT)\n\n# seed\nset.seed(1234)\n\nOne setting includes the specification of:\n\nStudy design\nAssumptions about fidelity pattern\nModel parameter\nIterations of the simulation\n\nand finally,\n\nthe simulation experiment can be performed.\n\n\nStudy design\nBased on the study setup, the following parameters for the study design need to be defined:\n\nNo. of clusters (e.g hospitals)\nNo. of individuals per cluster (and time point) as the cluster size\nNo. of time points the cluster were followed\nDesign type controls if individuals will be followed over time (cross-sectional or longitudinal): cross-sectional type, which indicates trials where individuals within the cluster can change over time points (however this design indicator is not necessary for conducting the design matrix)\n\nA design matrix according the study design has to be determined by the function designMatrix(). Here, two arguments are specific for the different types of studies. If the design = 'parallel', then the parameter nSW indicates the number of clusters as being the control group. If choosing design = 'SWD' (which is also set by default), the parameter nSW indicates the number of cluster-switches per time point from control to intervention group (which highly dependent on the number of clusters and time points).\nFor our example we will use the following parameter:\n\nNumber of clusters: 6\nCluster size: 10\n\nNumber of time points: 7\nCross-sectional design\n\nand 3 clusters are in the control and 3 clusters in the intervention group.\nIn the next step we determine the corresponding design matrix for a parallel cluster randomized study with this specific set of design parameters as follows:\n\n## Design matrix ##\n\nI &lt;- 6      # number of clusters\nJ &lt;- 10     # number of individuals per cluster (used later in simulation-step)\nK &lt;- 7      # number of time points\nSw &lt;- 1     # number of cluster switches per time point can be manually set\ntype &lt;- \"cross-sec\" #Cross-sectional design, indicates that \n#individuals within the cluster can change over time points\n\n# design matrix for parallel design\n(designMat_prll &lt;- designMatrix(\n  nC = I, nT = K, nSw = round(I / 2),\n  design = \"parallel\"\n))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    0    0    0    0    0    0\n[2,]    0    0    0    0    0    0    0\n[3,]    0    0    0    0    0    0    0\n[4,]    1    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1    1\n[6,]    1    1    1    1    1    1    1\n\n\n\n\nAssumptions about fidelity pattern\nThe following step is a central part of this tutorial. We want to examine different fidelity patterns and their implications for the study effects.\nTo simulate a specific fidelity pattern, a second design matrix indicating the pattern of fidelity has to be provided and indicates if there are deviations from the perfect situation (100% fidelity) present or not. For the simulation we have to add fractional values according to the chosen fidelity pattern. There are 3 functions within the R-package {fidelitysim} that can be used to specify several fidelity patterns. The patterns can be specified based on a slow, linear or fast increase and the respective start and end value for fidelity. For further explanation of fidelity patterns see Section 3.3. The selected fidelity patterns can then be pushed to the design matrix with the R-package {samplingDataCRT}, for more explanation see Section 3.2.\nFor our example we use the same design parameters, i.e. parallel cluster randomized trial, 6 timepoints, etc. and assume a linear increase of fidelity from 40% to 80% from the first measurement point after introduction of the intervention to the final measurement point (time point K). Based on these parameters we will create a new design matrix X.A that incorporates fractional values based on the provided fidelity pattern. This new design matrix will be used as a reference matrix in our simulation.\n\n\n\n\n\n\n\n\n3 arguments have to be specified to determine the fidelity pattern using the provided function find.Fidelity.linear:\n\n### Fidelity parameters ###\n\n# Fidelity at the begin\nFid.T1 &lt;- 0.4\n# Fidelity at the end\nFid.End &lt;- 0.8\n\n# slope for linear function\nm &lt;- (Fid.T1 - Fid.End) / (1 - (K - 1))\n\n\n# model linear increase\nres.lin &lt;- find.Fidelity.linear(time.points = K, Fid.End, Fid.T1)\n\n(The application of the other two functions for slow (exponential) and fast (logarithmic) increase are shown in Section 3.3.)\nThen, we create the new design matrix using the function implemMatrix.parallel :\n\n# design matrix of a linear fidelity pattern\n(fidelMat_prll &lt;- implemMatrix.parallel(\n  nC = I, nT = K, nSw = round(I / 2),\n  pattern = res.lin[, \"Fidelity.Prozent\"] / 100\n))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[2,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[3,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[4,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[5,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[6,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n\n\nThis matrix reflect the fidelity pattern including the implementation error (deviation form 100%). Both design matrices are later used for the simulation as arguments X = designMat_prll and X.A = fidelMat_prll for simulation Section 2.1.5. In a perfect situation - where we assume 100% fidelity at every time point, both matrices are the same.\n\n\nSpecifying model parameter\nIn addition to the design parameters, we have to define the following model parameters as well:\n\nBaseline mean of the outcome of interest (e.g. mean quality of life score) \\(\\mu_0\\)\nIntervention effect (the change of scores after intervention) \\(\\Theta\\)\nIntra-cluster correlation coefficient ICC (between cluster and error variance \\(\\sigma_c\\), \\(\\sigma_e\\) )\n\nIf applicable: time trend (effect of each time point during followed time points)\n\n\nFor our example we use the following model parameter:\n\nbaseline mean = 10\nintervention effect = 1\nno time trend\nICC of 0.001\n\n\n## Model parameter ##\n\nmu.0 &lt;- 10 # Baseline mean of the outcome of interest\ntheta &lt;- 1 # Intervention effect\nbetas &lt;- rep(0, K - 1) # no time trend, but could be included\n\n# variability within or error variance (H&H sigma)\nsigma.1 &lt;- 2 \n# variability within clusters, if longitudina data\nsigma.2 &lt;- NULL \n# between clusters variability (H&H tau)\nsigma.3 &lt;- sigma.1 * sqrt(0.001 / (1 - 0.001)) \n\n# resulting ICC\n(ICC &lt;- sigma.3^2 / (sigma.3^2 + sigma.1^2))\n\n[1] 0.001\n\n\nWhen choosing a longitudinal instead of a cross-sectional design a third variance needs to be specified (see for more detail into Section 3.1.2).\n\n\nDefining number of iterations for the simulation\nIn addition to the parameters set above, we need to define the number of iterations for the simulation. The number determines how often the sampling and estimation should be repeated to finally calculate the performance measures. In the literature 10,000 and 100,000 iterations are recommended to obtain valid results, however, this validity comes at a time cost. In our example we will set n = 1,000 iterations with regard to the computing time (and can be set by the user under consideration of their machine’s computational power).\n\n## Number of iterations of the simulation ##\nanzSim &lt;- 1000\n\n\n\nSimulation experiment\nSince we set all necessary arguments for the usage of the provided simulation function:\n\nStudy design\nModel parameter\nIndication if there are deviations from perfect situations or not\nIterations of the simulation\n\nwe can start the simulation by using the provided function simulation:\n\n# linear increase of fidelity\nres.Simu.parallel.lin &lt;- simulation(\n  anzSim = anzSim, #Simulation parameter\n  type = type, K = K, J = J, I = I, #design parameter\n  sigma.1 = sigma.1, sigma.3 = sigma.3, #model parameters\n  mu.0 = mu.0, theta = theta, betas = betas, #model parameters\n  X = designMat_prll, X.A = fidelMat_prll #design matrices\n)\n\nFor this design setting and number of iteration (n=1000), a computational time of 3.01 min is needed\nThe output of the simulation provides a total of n =22 results, among the following performance parameters (see also Section 2.1):\n\nBias\nCoverage\nPower\n\nThe mean estimate of the intervention effect from all iterations and the power of the design can be accessed like this:\n\n# mean estimated intervention effect\nround(res.Simu.parallel.lin[\"intervention Mean .\"],3)\n\nintervention Mean . \n              0.615 \n\n# estimated power\nround(res.Simu.parallel.lin[\"Power.Intervention\"],3)\n\nPower.Intervention \n             0.738 \n\n\nWe obtain a power of 0.738 to detect an intervention effect of 1 within an parallel study with 6 clusters followed 7 time points and a cluster size of 10 when an linear increase of the fidelity from 40% to 80% is achieved until end of the study."
  },
  {
    "objectID": "simulation-step-by-step.html#comparison-of-several-fidelity-patterns",
    "href": "simulation-step-by-step.html#comparison-of-several-fidelity-patterns",
    "title": "2  Step-by-step simulation",
    "section": "Comparison of several Fidelity patterns",
    "text": "Comparison of several Fidelity patterns\nTo compare the effect of different fidelity patterns, a repetition of the simulation has to be conducted.\nWe will continue with our example from before (see Section 2.1.1 - Section 2.1.3) and examine in total seven different fidelity patterns. We will assume (A) three types of slow increases, (B) one linear increase and (C) three types of fast increases of fidelity for this design setting (see Section 3.3 for further explanation) and compare with the perfect situation.\n\n\n\n\n\n\n\n\n\n### several Slopes indicating the degree of increase ###\nslope.seq&lt;-round(exp(1)^(seq(-2,2,2)),2)\nnr.sl&lt;-length(slope.seq)\n\nAt first, perfect situation simulation (no deviation from 100% implementation).\n\n################################\n# perfect implementation\n# no individual or cluster miss\n################################\n\n#design matrix of perfect situation\nX&lt;-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=round(I/2), design=\"parallel\")\nres&lt;-fidelitysim::simulation(\n                  anzSim=anzSim, #Simulation parameter\n                  type=\"cross-sec\", K=K,J=J,I=I, #design paramter\n                  sigma.1=sigma.1,sigma.3=sigma.3, #model parameters\n                  mu.0=mu.0, theta=theta,betas=betas,\n                  X=X, X.A=X #design matrices\n                  )\nres&lt;-as.data.frame(t(res))\n\nNext for (A) several slow increase (reflected by an exponential function):\n\n###all the other patterns\nres.Simu&lt;-data.frame()\n\n#exponential increase\nfor(sl in 1:nr.sl){#for each slope\n    \n   #Fidelity pattern\n    res.exp&lt;-fidelitysim::find.Fidelity.exp(time.points=K, \n                               Fid.End, Fid.T1, \n                               par.slope=slope.seq[sl])\n    #new design matrix\n    A1.exp &lt;-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                               pattern=res.exp[,\"Fidelity.Prozent\"]/100)\n     #simulation experiment  \n    res&lt;-fidelitysim::simulation(anzSim=anzSim,\n                    type=\"cross-sec\",  K=K,J=J,I=I,\n                    sigma.1=sigma.1,sigma.3=sigma.3,\n                    mu.0=mu.0, theta=theta,betas=betas,\n                    X=X, X.A=A1.exp\n                    )\n    res&lt;-as.data.frame(t(res))\n    #save results\n    res.Simu&lt;-rbind(res.Simu,\n                   data.frame( res, \n                      D=\"exp\", slope=slope.seq[sl], sort=2+nr.sl+(nr.sl-sl+1), \n                      Fid.Begin=Fid.T1, Fid.END=Fid.End)\n    )\n\n}\n\nFor (B) linear increase:\n\n##linear increase\nm&lt;-(Fid.T1-Fid.End)/(1-(K-1))\n#Fidelity pattern\nres.lin&lt;-fidelitysim::find.Fidelity.linear(time.points=K, Fid.End, Fid.T1)\n#ne design matrix\nA1.lin &lt;-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                               pattern=res.lin[,\"Fidelity.Prozent\"]/100)\n#simulation experiment\nres&lt;-fidelitysim::simulation(anzSim=anzSim,\n                type=\"cross-sec\", K=K,J=J,I=I,\n                sigma.1=sigma.1,sigma.3=sigma.3,\n                mu.0=mu.0, theta=theta,betas=betas,\n                X=X, X.A=A1.lin)\nres&lt;-as.data.frame(t(res))\n\nFor (C) several fast increase (reflected by a logarithmic function):\n\n###all the other patterns\nres.Simu&lt;-data.frame()\n\n#logistic increase\nfor(sl in 1:nr.sl){#for each slope\n    #Fidelity pattern\n    res.log&lt;-fidelitysim::find.Fidelity.log(time.points=K, \n                               Fid.End, Fid.T1, \n                               par.slope=slope.seq[sl])\n    #new design matrix\n    A1.log &lt;-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                                   pattern=res.log[,\"Fidelity.Prozent\"]/100)\n    #simulation experiment\n    res&lt;-fidelitysim::simulation(anzSim=anzSim,\n                    type=\"cross-sec\", K=K,J=J,I=I,\n                    sigma.1=sigma.1,sigma.3=sigma.3,\n                    mu.0=mu.0, theta=theta,betas=betas,\n                    X=X, X.A=A1.log)\n    res&lt;-as.data.frame(t(res))\n    #save results\n    res.Simu&lt;-rbind(res.Simu,\n                   data.frame( res, \n                      D=\"log\", slope=slope.seq[sl], sort=1+sl, \n                      Fid.Begin=Fid.T1, Fid.END=Fid.End)\n    )\n  }\n\nFigure 2.2 summarizes the results of the simulation for different fidelity patterns regarding power of the study. The results shown are performed by 10,000 iterations for the simulation to have precise estimates. For this design setting and number of iteration (n=10,000), a computational time of 7 hours is needed.\n\n\n\n\n\nFigure 2.2: Results of simulation for several fidelity pattern scenarios"
  },
  {
    "objectID": "additional-statistical-info.html#explanation-of-simulation-experiment-and-provided-corresponding-function",
    "href": "additional-statistical-info.html#explanation-of-simulation-experiment-and-provided-corresponding-function",
    "title": "3  Detailed statistical information",
    "section": "Explanation of simulation experiment and provided corresponding function",
    "text": "Explanation of simulation experiment and provided corresponding function\nFor a simulation experiment it is not necessary to understand the whole statistical modeling background, which is figured out here.\nEach simulation step includes three necessary steps:\n\nDetermining the design matrix regarding the specified design\nSampling data\nEffect estimation from the data\n\nand will be explained with more detail in the following subsections.\nFor the first two steps, the R-package {samplingDataCRT} v1.0 (Trutschel and Treutler 2017) is needed, for the last {lme4} (Bates et al. 2015). The first step is done once and the latter two are used repeatedly through one simulation experiment within each scenario.\n\nDetermining the design matrix regarding the chosen design\nTo specify a cluster randomized study the following parameter has to be determined:\n\nNumber of clusters (e.g. hospitals, nursing homes, …) obtained through the study\nNumber of time points the clusters are followed\nCluster size refers to the number of individuals obtained within one cluster\nStudy design: parallel design or Stepped wedge design (cross-over as well possible)\nStudy type: cross-sectional if individuals could be different within the cluster between time points or longitudinal if individuals are followed over time\n\nBased on the example in the main article, we specify a hypothetical example including parameter settings for a reference setup of the simulation experiment: a cross-sectional stepped wedge cluster randomized trial with 6 nursing homes, 7 time points and 10 individuals within each nursing home and time point (see main article). All parameters can be adapted to an own practical example. The resulting reference design matrix can be create manually (by create a corresponding matrix) or by designMatrix().\n\n######################################################\n#using the parameter setting of Table 1 in the article\n######################################################\n\n## Design ##\n############\nK&lt;-7 #number of time points\nI&lt;-6 #number of cluster\nSw&lt;-1 #number of cluster switches per time point can be manually set\nJ&lt;-10 #Subjects =  Number of individuals per cluster\n\n#design matrix of \"SWD\" with given setting\n(X&lt;-samplingDataCRT::designMatrix(nC=I, nT=K, nSw=Sw))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    1    1    1    1    1    1\n[2,]    0    0    1    1    1    1    1\n[3,]    0    0    0    1    1    1    1\n[4,]    0    0    0    0    1    1    1\n[5,]    0    0    0    0    0    1    1\n[6,]    0    0    0    0    0    0    1\n\n\n\n\nSampling data of a cluster randomized trial with a given design\nTo sample data for a cluster randomized trial using sampling from a multivariate normal distribution provided by the package {samplingDataCRT}, several model parameter has also be specified:\n\nBaseline mean of the outcome of interest\nIntervention effect (change/difference in mean outcome) by implementing the intervention)\nTime trend effects\nVariance within the multilevel data: between clusters, between individuals, within individuals which provide an estimate of the intra-cluster correlation coefficient (ICC) as an measure of dependencies within clusters.\n\nIn the example here we set the mean outcome to 10 (e.g. the mean population value of measured quality of life), the intervention effect which aimed to change quality of life of 1, and no time trends. With a given between cluster variance of sigma.3 and a error variance of sigma.1, the resulting ICC is ICC.\n\n## Model parameter ##\n####################\nmu.0&lt;- 10           # Baseline mean of the outcome of interest\ntheta &lt;- 1          # intervention effect\nbetas&lt;-rep(0, K-1)  # no Time trend, but could be included\n\n# variability within or error variance (H&H sigma)\nsigma.1&lt;-2    \n# variability within clusters, if longitudinal data\nsigma.2&lt;-NULL\n# between clusters variability (H&H tau)\nsigma.3&lt;-sigma.1*sqrt(0.001/(1-0.001))    \n\n#resulting ICC\n(ICC&lt;-sigma.3^2/(sigma.3^2+sigma.1^2))\n\n[1] 0.001\n\n\nTo note, by choosing longitudinal or cross-sectional design, we need to specify in the first case 3, in the second only two variances regarding using a three- instead of a two-level hierarchical experiment with the following meaning:\n\nthree-level design (longitudinal data):\n\nbetween clusters variability\nwithin cluster (or between individuals) variability\nwithin individuals (or error) variability\n\ntwo-level design (cross-sectional data):\n\nbetween clusters variability \\(\\sigma\\) (Hussey and Hughes 2007)\nwithin cluster (or error) variability \\(\\tau\\) (Hussey and Hughes 2007)\n\n\nA complete data set for a special design with a given setup can be sampled by the function sampleData(). Therefore,the complete data design matrix and the covariance-variance matrix for the data given the design are also needed to be specified with completeDataDesignMatrix() and CovMat.Design(). The complete data design matrix has the size of (Number of cluster x cluster size x Number of time points) rows and (Number of model parameters) columns. To sample the data from for a cluster randomized trial, it has additionally be specified, if the individuals are followed over time (longitudinal design) or not (cross-sectional design).\n\n#complete data design matrix\nD&lt;-samplingDataCRT::completeDataDesignMatrix(J, X)\n(dim(D))\n\n[1] 420   8\n\n#covariance-variance matrix for the data given the design\nV&lt;-samplingDataCRT::CovMat.Design(K, J, I, sigma.1=sigma.1, sigma.3=sigma.3)\ndim(V)\n\n[1] 420 420\n\n#corresponding fixed effects in linear mixed model\nparameters&lt;-c(mu.0, betas, theta)\n\n#sample complete data given the setup\n# study design type = cross-sectional\ntype&lt;-\"cross-sec\" \nsample.data&lt;-samplingDataCRT::sampleData(type = type, K=K,J=J,I=I, \n                                         D=D, V=V, parameters=parameters)\n\nTo validate the number of observations provided by the sampling method a summary of the data can be conducted.\n\ndim(sample.data)\n\n[1] 420   5\n\n#show the number of observations within the SWD\nxtabs(~cluster+measurement, data=sample.data)\n\n       measurement\ncluster  1  2  3  4  5  6  7\n      1 10 10 10 10 10 10 10\n      2 10 10 10 10 10 10 10\n      3 10 10 10 10 10 10 10\n      4 10 10 10 10 10 10 10\n      5 10 10 10 10 10 10 10\n      6 10 10 10 10 10 10 10\n\n\n\n\nEffect estimation from the data\nThe sampled data can then be analyzed by a linear mixed model with lme4::lmer(), where the parameter of the model will be estimated.\n\n#analysis of the two-level data by a linear mixe model\nlme4::lmer(val~intervention+measurement + (1|cluster), data=sample.data)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: val ~ intervention + measurement + (1 | cluster)\n   Data: sample.data\nREML criterion at convergence: 1475.386\nRandom effects:\n Groups   Name        Std.Dev.\n cluster  (Intercept) 0.3484  \n Residual             1.3800  \nNumber of obs: 420, groups:  cluster, 6\nFixed Effects:\n (Intercept)  intervention  measurement2  measurement3  measurement4  \n      9.6904        0.8622        0.1668        0.3584        0.3356  \nmeasurement5  measurement6  measurement7  \n      0.7371        0.4026        0.5050  \n\n\nThis process of sampling data and effect estimation from the data will be used repeatedly through the simulation experiment within each scenario setting."
  },
  {
    "objectID": "additional-statistical-info.html#sec-determinediffdesignmatrix",
    "href": "additional-statistical-info.html#sec-determinediffdesignmatrix",
    "title": "3  Detailed statistical information",
    "section": "Determine differrent design matrices",
    "text": "Determine differrent design matrices\nThe function designMatrix() of the R-package {samplingDataCRT} provides the design matrix of cluster randomized trials with several study designs, given the number of clusters, time points and cluster size assumed for the trial. We show here for two examples:\n\nparallel\nSWD\n\n\nParallel cluster randomized trials\nWithin the function the design argument is set to ‘parallel’,\nand the parameter nSW indicates the number of clusters that are being control group.\n\n## Design paramter ##\n######################\nI &lt;- 6 # number of clusters\nJ &lt;- 10 # number of individuals per cluster (used later in simulation-step)\nK &lt;- 7 # number of time points\nSw &lt;- round(I / 2) # number of cluster within the control group\n\n# design matrix for parallel design\n(designMat_prll &lt;- samplingDataCRT::designMatrix(nC = I, nT = K, nSw = round(I / 2), \n                                                 design = \"parallel\"))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    0    0    0    0    0    0\n[2,]    0    0    0    0    0    0    0\n[3,]    0    0    0    0    0    0    0\n[4,]    1    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1    1\n[6,]    1    1    1    1    1    1    1\n\n\n\n\nStepped wedge cluster randomized trial\nWhereas the design parameters can be the same as in the parallel study the design matrix differs accordingly when changing the argument design = \"SWD\" (which is also set by default, so it has not to be specified). The parameter ‘nSW’ indicates here the number of cluster switches per time point from control to intervention group.\n\n## Design matrix ##\n\nI &lt;- 6 # number of clusters\nJ &lt;- 10 # number of individuals per cluster (used later in simulation-step)\nK &lt;- 7 # number of time points\nSw &lt;- 1 # number of cluster switches per time point can be manually set\n\n# design matrix of \"SWD\"\n(designMat_SWD &lt;- samplingDataCRT::designMatrix(nC = I, nT = K, \n                                                nSw = Sw, design = \"SWD\"))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    1    1    1    1    1    1\n[2,]    0    0    1    1    1    1    1\n[3,]    0    0    0    1    1    1    1\n[4,]    0    0    0    0    1    1    1\n[5,]    0    0    0    0    0    1    1\n[6,]    0    0    0    0    0    0    1"
  },
  {
    "objectID": "additional-statistical-info.html#sec-fidpatterns",
    "href": "additional-statistical-info.html#sec-fidpatterns",
    "title": "3  Detailed statistical information",
    "section": "Determine different fidelity patterns",
    "text": "Determine different fidelity patterns\nFidelity refers to the degree to which an intervention was implemented as it was prescribed or intended. We aim to include different patterns of how fidelity might increase over time to estimate the respective effects on power of the study. To describe hypothetical fidelity patterns of increasing fidelity (slow, linear, fast) different mathematical functions (i.e. logistic, linear and exponential curves) are implemented. By considering different values for the slope parameter we can cover a range of fidelity patterns. The slope parameter ranges form \\((0,\\infty)\\), where a slope parameter near to \\(0\\) indicates a increase far away from a linear (fast increase upper left corner, slow increase right bottom corner curve) and a great slope parameter near to linear (see Figure 3.1 ).\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n#study design\n#############\n#number of measurement\nK&lt;-7  \n#points of time afterintervention\nT.points&lt;-K-1\n\n#parameter Fidelity specification\n###############################\nFid.T1&lt;-0.2\nFid.End&lt;-1\n\n####set several slopes of increasing fidelity\n#######################################\nslope.seq&lt;-round(exp(1)^(seq(-2,2,1)),2)\nnr.sl&lt;-length(slope.seq)\n\n####fidelity patterns determined by several slopes within slow and fast increase\n##############################################################################\nres.plot.Patterns&lt;-NULL\nfor(sl in slope.seq){\n res&lt;-fidelitysim::find.Fidelity.log(time.points=T.points, Fid.End, Fid.T1, \n                                     par.slope=sl)\n res&lt;-data.frame(res, FUN=\"log\", slope=sl)\n res.plot.Patterns&lt;-rbind(res.plot.Patterns, res)\n res&lt;-fidelitysim::find.Fidelity.exp(time.points=T.points, Fid.End, Fid.T1, \n                                     par.slope=sl)\n res&lt;-data.frame(res, FUN=\"exp\", slope=sl)\n res.plot.Patterns&lt;-rbind(res.plot.Patterns, res)\n      \n}\n\n#fidelity pattern for linear increase\n#####################################\nres.lin&lt;-fidelitysim::find.Fidelity.linear(time.points=T.points, Fid.End, Fid.T1)\nres.plot.Patterns&lt;-rbind(res.plot.Patterns, data.frame(res.lin, FUN=\"linear\", \n                                                       slope=1))\n\n\n\n\n\n\nFigure 3.1: Patterns of a fidelity increase (fast, linear or slow) over 6 times points\n\n\n\n\nFor our calculation within the simulation we use the determined fractional values of intervention effects to define the degree of deviation from 100% implementation within the design matrix. Three functions in {fidelitysim} provide the implementation of the different patterns of fidelity.\n\nSlow increase of fidelity using exponential function\nHere we show an example how to determine the design matrix for a cluster randomized parallel design study (with same design as above) with existing implementation error, where fidelity starts with 40% after implementation and reach after a slow increase 80% at the end of the study. A great slope parameter is chosen which reflect a slow increase more closed to the linear increase.\n\n#study design\n#############\nI &lt;- 6 # number of clusters\nJ &lt;- 10 # number of individuals per cluster (used later in simulation-step)\nK &lt;- 7 # number of time points\nSw&lt;- round(I/2) # number of cluster within the control group\n\n#parameter Fidelity specification\n###############################\nFid.T1&lt;-0.4\nFid.End&lt;-0.8\n\n#parameter tunes the slope for the log and exp functions\nslope.seq&lt;-5\n  \n#exponential function to determine slow increase\n(res.exp&lt;-fidelitysim::find.Fidelity.exp(time.points=K, Fid.End, Fid.T1, \n                                         par.slope=slope.seq))\n\n     time Fidelity.Prozent\n[1,]    1               40\n[2,]    2               44\n[3,]    3               49\n[4,]    4               55\n[5,]    5               62\n[6,]    6               70\n[7,]    7               80\n\n#determine correspondingdesign matrix\n(A1.exp &lt;-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=Sw, \n                                pattern=res.exp[,\"Fidelity.Prozent\"]/100))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00 0.00 0.00  0.0  0.0\n[2,]  0.0 0.00 0.00 0.00 0.00  0.0  0.0\n[3,]  0.0 0.00 0.00 0.00 0.00  0.0  0.0\n[4,]  0.4 0.44 0.49 0.55 0.62  0.7  0.8\n[5,]  0.4 0.44 0.49 0.55 0.62  0.7  0.8\n[6,]  0.4 0.44 0.49 0.55 0.62  0.7  0.8\n\n\n\n\nLinear increase of fidelity using linear function\nHere we show an example how to determine the design matrix for a cluster randomized parallel design study (with same design as above) with existing implementation error, where fidelity starts with 40% after implementation and reach after a linear increase 80% at the end of the study.\n\n#parameter Fidelity specification\n###############################\nFid.T1&lt;-0.4\nFid.End&lt;-0.8\n\n\n#slope for linear function\nm&lt;-(Fid.T1-Fid.End)/(1-(K-1))\n\n#linear increase\n(res.lin&lt;-fidelitysim::find.Fidelity.linear(time.points=K, Fid.End, Fid.T1))\n\n     time Fidelity.Prozent\n[1,]    1               40\n[2,]    2               47\n[3,]    3               53\n[4,]    4               60\n[5,]    5               67\n[6,]    6               73\n[7,]    7               80\n\n# design matrix of a learning impelementation pattern, linear\n(A1.lin &lt;-fidelitysim::implemMatrix.parallel(nC=I, nT=K, nSw=round(I/2), \n                                pattern=res.lin[,\"Fidelity.Prozent\"]/100))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[2,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[3,]  0.0 0.00 0.00  0.0 0.00 0.00  0.0\n[4,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[5,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n[6,]  0.4 0.47 0.53  0.6 0.67 0.73  0.8\n\n\n\n\nFast increase of fidelity using logarithmic function\nHere we show an example how to determine the design matrix for a cluster randomized stepped wedge design study (with same design as above) with existing implementation error, where fidelity starts with 20% after implementation and reach after a fast increase 100% at the end of the study. A small slope parameter is chosen for determining the fidelity curve, which reflect a very fast increase.\n\nSw &lt;- 1 # number of cluster switches per time point can be manually set\n\n#parameter Fidelity specification\n###############################\nFid.T1&lt;-0.2\nFid.End&lt;-1\n\n#parameter tunes the slope for the log and exp functions\nslope.seq&lt;-0.2\n\n#logistic function to determine fast increase\n(res.log&lt;-fidelitysim::find.Fidelity.log(time.points=K-1, Fid.End, Fid.T1, \n                                         par.slope=slope.seq))\n\n     time Fidelity.Prozent\n[1,]    1               20\n[2,]    2               95\n[3,]    3               97\n[4,]    4               98\n[5,]    5               99\n[6,]    6              100\n\n(A1.log &lt;-samplingDataCRT::implemMatrix.SWD(nC=I, nT=K, nSw=Sw, \n                                pattern=res.log[,\"Fidelity.Prozent\"]/100))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0  0.2 0.95 0.97 0.98 0.99 1.00\n[2,]    0  0.0 0.20 0.95 0.97 0.98 0.99\n[3,]    0  0.0 0.00 0.20 0.95 0.97 0.98\n[4,]    0  0.0 0.00 0.00 0.20 0.95 0.97\n[5,]    0  0.0 0.00 0.00 0.00 0.20 0.95\n[6,]    0  0.0 0.00 0.00 0.00 0.00 0.20\n\n\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nHussey, Michael A., and James P. Hughes. 2007. “Design and Analysis of Stepped Wedge Cluster Randomized Trials.” Contemporary Clinical Trials 28 (2): 182–91. https://doi.org/https://doi.org/10.1016/j.cct.2006.05.007.\n\n\nTrutschel, Diana, and Hendrik Treutler. 2017. samplingDataCRT: Sampling Data Within Different Study Designs for Cluster Randomized Trials. https://CRAN.R-project.org/package=samplingDataCRT."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.\n“Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical\nSoftware 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nHussey, Michael A., and James P. Hughes. 2007. “Design and\nAnalysis of Stepped Wedge Cluster Randomized Trials.”\nContemporary Clinical Trials 28 (2): 182–91. https://doi.org/https://doi.org/10.1016/j.cct.2006.05.007.\n\n\nR Core Team. 2022. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nTrutschel, Diana, and Catherine Blatter. 2022. fidelitysim: Simulations Experiments for Cluster\nRandomized Trials Having Fidelity Patterns for Implementation Science\nResearch.\n\n\nTrutschel, Diana, and Hendrik Treutler. 2017. samplingDataCRT: Sampling Data Within Different\nStudy Designs for Cluster Randomized Trials. https://CRAN.R-project.org/package=samplingDataCRT.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data\nAnalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org."
  }
]